{"componentChunkName":"component---src-pages-applications-m-2-m-index-mdx","path":"/applications/m2m/","result":{"pageContext":{"frontmatter":{"title":"Getting Started with IBM Mono2Micro","description":null},"relativePagePath":"/applications/m2m/index.mdx","titleType":"append","MdxNode":{"id":"2cfced74-45e1-5872-9421-7eb0b52f345d","children":[],"parent":"fe253f10-a042-58f5-90f0-0d8df3746cfe","internal":{"content":"---\ntitle: Getting Started with IBM Mono2Micro\ndescription: \n---\nOne of the best ways to modernize business applications is to refactor them into microservices, allowing each microservice to be then independently enhanced and scaled, providing agility and improved speed of delivery. \n\nIBM Mono2Micro is an AI-based semi-automated toolset that uses novel machine learning algorithms and a first-of-its-kind code generation technology to assist you in that refactoring journey to full or partial microservices, all without rewriting the Java application and the business logic within. \n\nIt analyzes the monolith application in both a static and dynamic fashion, and then provides recommendations for how the monolith can be partitioned into groups of classes that can become potential microservices. \nBased on the partitioning, Mono2Micro also generates the microservices foundation code and APIs which alongside the existing monolith Java classes can be used to implement and deploy running microservices.\n\n![](images/1-m2m.png)\n\n### **1. Business Scenario**\n\nYour company has a traditional WebSphere Application Server application called **DefaultApplication**, a monolith web application provides the following servlet functions:\n\n![](images/7-default-app.png)\n\n**Snoop servlet**\n\nUse the Snoop servlet to retrieve information about a servlet request. This servlet returns the following information:\n \n  * Servlet initialization parameters\n  * Servlet context initialization parameters\n  * URL invocation request parameters\n  * Preferred client locale\n  * Context path\n  * User principal\n  * Request headers and their values\n  * Request parameter names and their values\n  * HTTPS protocol information\n  * Servlet request attributes and their values\n  * HTTP session information\n  * Session attributes and their values\n\nThe Snoop servlet includes security configuration so that when WebSphere Security is enabled, clients must supply a user ID and password to initiate the servlet.\n\n**HitCount application**\n\nUse the HitCount demonstration application to demonstrate how to increment a counter using a variety of methods, including:\n  * A servlet instance variable\n  * An HTTP session\n  * An enterprise bean\n\nYou can instruct the servlet to execute any of these methods within a transaction that you can commit or roll back. If the transaction is committed, the counter is incremented. If the transaction is rolled back, the counter is not incremented.\n\nThe enterprise bean method uses a container-managed persistence enterprise bean that persists the counter value to an Apache Derby database. This enterprise bean is configured to use the DefaultApp Datasource, which is set to the DefaultDB database.\n\nWhen using the enterprise bean method, you can instruct the servlet to look up the enterprise bean, either in the WebSphere global namespace, or in the namespace local to the application.\n\n\nAs a tech leader, you are leading the effort to use IBM Mono2Micro to transform the monolith application to Microservices.\n\n### **2. Getting Started with Mono2Micro**\n\nBelow is a high-level flow diagram of getting started with Mono2Micro in collecting data on an existing monolith application, and then running the AI analyzer tool to generate two kinds of recommendations as how to partition the application into recommended microservices.\n\n![](images/2-m2m-flow.png)\n\n  *\tThe data is collected from static code analysis, capturing data (Class) dependencies, depicted in [1].\n  *\tData is dynamically collected through runtime trace logs as the instrumented monolith application is run through various use case scenarios to exercise as much of the codebase as possible, depicted in [2] & [3].  \n\nBased on all three kinds of data, Mono2Micro generates a Natural Seams Partitioning recommendation that aims to partition and group the monolith classes such that there are minimal class containment dependencies and entanglements (i.e. classes calling methods outside their partitions) between the partitions. \n\nThe **Data Dependency Analysis** in [1] refers to this kind of dependency analysis between the Java classes. In effect, this breaks up the monolith along its natural seams with the least amount of disruption.\n\nBased on [2] and [3] alone, and not taking class containment dependencies and method call entanglements into account, Mono2Micro also generates a Business Logic Partitioning that might present more entanglements and dependencies between partitions, but ultimately provides a more useful partitioning of the monolith divided along functional and business logic capabilities.\n\n#### **2.1. How does Mono2Micro work?**\n\nIn this lab, you will use a simple JEE monolith application named **DefaultApplication**, and step through the entire Mono2Micro toolset, end to end, starting with the monolith and ending with a deployed and containerized microservices version of the same application. \n\nMono2Micro consists of five components, each of them serves a specific purpose. The component and their uses are listed in the following:\n\n**Bluejay** - instruments the Java source code of monoliths. The instrumentation captures entry and exit of every Java method in the application. \n\n**Flicker** - A Java program that is used while running test cases that gathers runtime analysis data. Flick is used to align the start and end times of a use case with the timestamps generated from the instrumented code. This allows for Mono2Micro to track the code being executed in the monolith to specific use cases.  \n\n**AIPL** - The AI engine of Mono2Micro which uses machine learning and deep learning techniques on the user supplied runtime traces and metadata obtained from Bluejay and Flicker to generate microservice recommendations. AIPL also produces a detailed report for the recommended microservices.\n\n**Mono2Micro UI** - The results obtained from AIPL are stored in userâ€™s local storage. The results can be uploaded to Mono2Micro UI to display them in a graphical visualizer. The UI also allows user to modify the AIPL generated microservice recommendations.\n\n**Cardinal** - The program with deep knowledge of the semantics of the Java programming language. Cardinal uses the recommendations from AIPL. \n\nCardinal performs these important capabilities:\n  *\tProvides detailed invocation analyses of the recommended microservices\n  *\tGenerates a significant portion of the code needed to realize the recommended microservices in containers\n\n#### **2.2. Mono2Micro usage flow**\n\nThe illustration below shows how the Mono2Micro components fit into the end-to-end process. \n\n![](images/3-m2m-flow.png)\n\nAt this point, do not get bogged down with the details in the diagram. You will explore these details as you progress through the lab. \n  *\tUse Bluejay to instrument the monolith application\n  *\tUse Flicker and run test cases to capture runtime execution Trace data in the server logs, based on the instrumented code, updated by Bluejay.  \n  *\tUse AIPL to analyze the data and produce recommended microservices based on Natural Seams and/or Business logic. \n  *\tUse Mono2Micro UI to visualize the microservices recommendations, and tweak the recommendations as needed to meet your objectives.  \n  *\tUse Cardinal to generate the plumbing and service code needed to realize the recommended microservices. \n\n### **3. Objective**\n\nThe objectives of this lab are to help you:\n  * Learn how to perform the end-to-end process of using Mono2Micro to analyze a Java EE monolith and to transform it to Microservices\n  *\tLearn how to build and run the transformed microservices in containers using Docker and OpenLiberty\n\n### **4. Prerequisites**\n\nThe following prerequisites must be completed prior to beginning this lab:\n  *\t3 GB free storage for the Mono2Micro Docker images and containerized microservices\n  *\tDocker 17.06 CE or higher, which supports multi-stage builds\n  *\tGit CLI (needed to clone the GitHub repo)\n  *\tJava 1.8  \n  *\tMaven 3.6.3\n  *\tInternet connectivity with access to dockerhub and maven-central\n  *\tUnderstanding of command line for your environment \n\n### **5.\tWhat is Already Completed**\n\nOne (1) Linux CentOS version 7 VM has been provided for this lab. \n\n![](images/4-vm.png)\n\nUse the link below to reserve your Lab environment:\n\nhttps://dte2.us1a.cirrus.ibm.com/my/reservations/create/5fd399855bdac2001e0d42f8\n\nThe Workstation VM has the following software installed (you can use your own workstation with the same configurations):\n  *\tDocker 19.03.13\n  *\tGit 2.24.1\n  *\tMaven 3.6.3\n  *\tJava OpenJDK 1.8.0\n\nThe login credentials for the Workstation VM are:\n\nUser ID: **ibmadmin**\n\nPassword: **passw0rd**          \n\n**Note: You can also use your own workstation as the lab environment with the same configuration listed above. You only need to make three changes highlighted in Appendix C.**\n \n### **6.\tLab Tasks**\nDuring this lab, you complete the following tasks:\n  *\tLogin to the Workstation VM and Get Started\n  * Build and run the Transformed Java Microservices Using Docker\n  * Use Mono2Micro to analyze the Java EE monolith application and recommend microservices partitions\n  * Generating Initial Microservices Foundation Code\n\n### **7.\tExecute Lab Tasks**\n\n#### **7.1. Log in to the Workstation VM and get started** \n\n**_1.**  If the VM is not already started, start it by clicking the Play button.\n \n![](images/5-start-vm.png)\n\n**_2.**\tAfter the VM is started, click the Workstation VM icon to access it. \n \n![](images/6-select-vm.png)\n\n**_3.**\tEnter the password as **passw0rd** and log in.\n\nThe Workstation Desktop is displayed. You execute all the lab tasks on this VM.\n\n### **Part 1**\n#### **7.2. Build and run the Transformed Java Microservices Using Docker**\n\nBefore you get started using Mono2Micro to transform a monolith application to Microservices, letâ€™s fast forward to the end results and see the transformed microservices in action. \n\nThe resources we provide for this lab includes the **Completed and Transformed** Microservices as a result of using Mono2Mico. \n\nThe goal here is to just let you see the transformed Microservices in a working state before you work through the transformation process yourself. \n\n**Objectives**\n  *\tSee the transformed monolith application running as independent microservices on OpenLiberty in separate Docker containers, before you use Mono2Micro to transform the monolith in this lab.\n  *\tLearn how to build and run the transformed microservices with Docker and OpenLiberty\n\nIn this part of the lab, you build and deploy the microservices that have already been transformed using Mono2Micro. \n\nYou leverage new and updated build components that have been created in Mono2Micro refactoring phase in order to build and run the microservices as independent OpenLiberty server runtimes in Docker containers. \n\nThe basic steps in this part of the lab include: \n  *\tClone the GitHub repository that contains the resources required for the lab\n  *\tUse Docker to build the two transformed microservices for the application \n  *\tSetup a local Docker Network for the local docker containers to communicate\n  * Start the docker containers and run the microservices based application\n  *\tView the microservices logs to see the communication and data flowing between the services as you test the application from a web browser\n\nThe GitHub repository contains all the source code and files needed to perform all the steps for using Mono2micro to transform the monolith application used in this lab to microservices, including:\n  * The DefaultApplication Source Code\n  *\tThe newly constructed dockerfiles to build and run the microservices in containers\n  *\tThe updated POM files that have been reduced to contain only the resources needed for the individual microservice\n \nStructure of the m2m-ws-sample GitHub repository is as follows (details in the README within the GitHub repo):\n  * Monolith source code: ./defaultapplication/monolith\n  * Monolith application data: ./defaultapplication/application-data/\n  * Mono2Micro analysis (initial recommendations): ./defaultapplication/mono2micro-analysis\n  * Mono2Micro analysis (further customized): ./defaultapplication/mono2micro-analysis-custom\n  * Deployable Microservices: ./defaultapplication/microservices\n\n**_1.**\tClone the GitHub repository by openning a Terminal window and running the following commands:\n\n```\ncd /home/ibmadmin\n\ngit clone https://github.com/kpostreich/m2m-ws-sample\n\n```\n\n![](images/8-git-clone.png)\n\n**_2.**\tChange to the directory that contains the artifacts needed to build and run the generated microservices in local Docker containers. The artifacts needed to build and run the two microservices, generated by Mono2Micro, are in the /home/ibmadmn/m2m-ws-sample/defaultapplication/microservices/ folder.\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/\n```\n\n**_3.** Build the resulting microservices in Docker containers\n\nLetâ€™s do a basic overview of the two microservices that form the DefaultApplication used in this lab.\n\nFirst, notice that there are two services. Mono2Micro places these services into logical partitions. The **web** partition is the UI front-end microservice. It includes the HTML, JSPs, and Servlets, all needed to run within the same Web Container, according to JEE specifications. The **partition0** partition is the backend service for the IncrementAction service. It contains an EJB and JPA component that is responsible for persisting the data to the embedded Derby database used by the microservice. \n \n![](images/9-web-partition0.png)\n\nWeb partition (front-end microservice) invokes partition0 (back-end), when the HitCount Service via EJB is executed by the user. \n\nWhat happens is the HitCount Servlet in the **Web partition** invokes a Rest Service interface in **partition0** through a local HitCount proxy, both generated by Mono2Micro as plumbing code for invoking the RESTful Microservices. \n\n![](images/10-web-partition0-details.png)\n\n**a.**\tCreate a Docker Network for the two containers to communicate.   \n    \nYou will use Docker to build and run the microservices based application. For the Docker containers to communicate, a local Docker network is required. \n\nTip: Later, when you launch the Docker containers, you will specify the network for the containers to join, as command line options. \n\n```\ndocker network create defaultappNetwork\n\ndocker network list\n```\n\n![](images/11-docker-network-list.png)\n\nNote: When using a Kubernetes based platform like RedHat OpenShift, the service to service communication is automatically handled by the underlying Kubernetes platform. \n \n**b.**\tBuild the defaultapplication-web (front-end) container.\n    \nThis container is the web front end service. It contains the html, jsp, and servlets. \n    \nThe defaultapp-web folder contains the Dockerfile used to build the front-end microservice. \n  \n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-web\n\ndocker build -t defaultapp-web  . | tee web.out\n```\n\nThe dockerfile performs these basic tasks:\n  *\tUses the projects pom.xml file to do a Maven build, which produces the deployable EAR. \n  *\tCopies the EAR file and OpenLiberty Server configuration file to the appropriate location in the Docker container for the microservice to start once the container is started.\n\n![](images/12-docker-build.png)\n\n**c.**\tStart the partition-web (front-end) docker container.\n\nNotice the command line options that are required for the microservice to run properly. \n  *\tThe partition-web container needs to expose port 9095 for the application to be invoked from a web browser. The OpenLiberty sever is configured to use HTTP port 9080 internally. \n  *\tThe container must be included in the defaultappNetwork that you defined earlier. The back-end microservice will also join this network allowing the services to communicate with one another. \n\n```\ndocker run --name=defaultapp-web --hostname=defaultapp-web --network=defaultappNetwork -d -p 9095:9080 defaultapp-web:latest\n\ndocker ps\n```\n  \n![](images/13-docker-ps.png)\n\nNote: The application is exposed on port 9095 and running on port 9080 in the container.\n \n**d.**\tBuild the defaultapplication-partition0 (back-end) container.\n\nThis container is the back-end service. It contains EJB and JPA components that persists data to the Derby database, when the user executes the HitCount service with the EJB option. \n\nTip: Ensure you are in the /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0 folder before running the docker build. \n\nThe default-partition0 folder contains the dockerfile used to build the back-end microservice. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0\n\ndocker build -t defaultapp-partition0 . | tee partition0.out\n```\n\nThe dockerfile performs these basic tasks:\n  *\tUses the projects pom.xml file to do a Maven build, which produces the deployable EAR. \n  *\tCopies the EAR file and OpenLiberty Server configuration file to the appropriate location in the Docker container for the microservice to start once the container is started.\n  *\tCopies the Derby Database library and database files to the container\n\n![](images/14-docker-build-partition0.png)\n\n**e.**\tStart the partition-partition0 (back-end) docker container.\n\nNotice the command line options that are required for the microservice to run properly. \n  *\tThe partition-partition0 container exposes port 9096.This is only necessary if we want to hit the Service interface directly while testing.\n  *\tThe container must be included in the defaultappNetwork that you defined earlier. \n\n```\ndocker run --name=defaultapp-partition0 --hostname=defaultapp-partition0 --network=defaultappNetwork -d -p 9096:9080 defaultapp-partition0:latest\n\ndocker ps\n```\n\n![](images/15-docker-ps-2.png)\n \nNote: The application is exposed on port 9096 and running on port 9080 in the container\n\n**f.**\tInspect Dockerâ€™s defaultappNetwork and ensure both microservices are joined in the network\n\n```\ndocker inspect defaultappNetwork\n```\n\n![](images/16-docker-inspect.png)\n\nThe microservices are now running on separate OpenLiberty servers in the local Docker environment. \n\nIn the next section, you will test the microservices application from a web browser.\n\n**_4.** View the OpenLiberty Server logs for the microservices\n\nAt this point, the microservices should be up and running inside of their respective docker containers. \n\nFirst, you look at the OpenLiberty server logs for both microservices to ensure the server and application started successfully. \n\n**a.** View the server log in the partition-web (front-end) docker container by running the following command to view the OpenLiberty Server log in the defaultapp-web container\n\n```\ndocker logs defaultapp-web\n```\n\n![](images/17-docker-logs.png)\n\nYou should see messages indicating the DefaultApplication and the defaultServer have been successfully started and is running.\n\t \n**b.** View the server log in the partition-partition0 (back-end) docker container by running the following command to view the OpenLiberty Server log in the defualtapp-web container\n\n```\ndocker logs defaultapp-partition0\n```\n\n![](images/18-docker-logs-partition0.png)\n    \nYou should see messages indicating the DefaultApplication and the defaultServer have been successfully started and is running.\n\n**_5.** Test the microservices from your local Docker environment\n\nOnce all the containers have started successfully, the DefaultApplication can be opened at http://localhost:9095/\n\nIn this section, you run the microservices based application, using the variety of options in the application user interface. \n\n**a.**\tLaunch a web browser and go to http://localhost:9095/\n \n![](images/19-defaultapp-9095.png)\n  \n**b.**\tClick the **Snoop Servlet** link to invoke it, which is running in the defaultapp-web (front-end) Microservice\n  \nThe Snoop Servlet requires authentication, as defined in the OpenLiberty server configuration. The credentials to access the Snoop servlet is: \n    \nUsername: **user1**\n    \nPassword: **change1me**\n\n![](images/20-login-credentials.png)\n\n  ![](images/21-snoop.png)\n\n**c.**\tClick the Browser back button to return to the **DefaultApplication** main page.\n \n![](images/22-defaultapp-back.png)\n    \nNext, you run the HitCount service. The HitCount service can be run using a variety of options that illustrate different mechanisms of handling application state in JEE applications. \n\nYou learn a little about the application that pertains to run the microservice based application that now makes distributed REST API calls between services.   \n    \nWhen using Mono2Micro for application analysis and microservice recommendations, we chose to separate the WEB UI components into a microservice and place the EJB components that interact with the back-end database into its own microservice. \n\nThis approach provides separation of the front-end from the back-end as a first pass for adopting a microservices architecture for the DefaultApplication. \n\nThis was not the only option, and we understand that further refactoring might be necessary. But this is a good first step to illustrate the capabilities of Mono2Micro.\n\nHere is a brief introduction to the multiple methods of running the HitCount Service. As illustrated below, selecting any of these three (3) options from the application UI, the HitCount service runs using the local Web Container session / state and runs the defaultapp-web (front-end) microservice. \n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\nSelecting the Enterprise Java Bean (JPA) option from the application, the Web front-end microservice calls out to the back-end microservice. \n  * Enterprise Java Bean (JPA)\n\nIt calls the IncrementAction REST service in the defaultapp-container0 container. The REST endpoint invokes an EJB which uses JPA to persist to the Derby database. Using this option also requires a selection for Transaction Type. \n    \n![](images/23-hit-count.png)\n  \n**d.**\tRun the HitCount service, choosing each of the three options below:\n\n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\nYou should see a message in the HTML page indicating the Hit Count value: An ERROR message is displayed in the event of an error. \n \n![](images/24-hit-count-value.png)\n\nTIP: The logging level in the Mono2Micro generated code has been set to **INFO** in the source code. \n\nThis means that logging statements will be generated in the server log file for all inter-partition calls. \n\nIn the defaultapp-web partition, the logs will show calling the IncrementAction Rest service running in defaultapp-partition0 (back-end) service  \n\nIn the defaultapp-partition0 (back-end) partition, the logs will show the response being sent back to the caller. \n\nSince using any of these options above run ONLY in the defaultapp-web (front-end) container, you will not see anything of significance logged in the server log files. This is expected behavior. \n  \n**e.** Run the HitCount service, choosing the Enterprise Java Bean (JPA) option.\n  \n**f.**\tInvoke the HitCount service multiple times, selecting different options for **Transaction Type**ã€‚\n\n**_6.**\tView the server logs from both microservices.\n  \nIn this case, the front-end microservice does call the back-end microservice, and you will see relevant messages in their corresponding log files. \n\n```\ndocker logs defaultapp-web\n\ndocker logs defaultapp-partition0\n``` \n\nOutput from defaultapp-web container \n \n![](images/25-output-web.png)\n\nOutput from defaultapp-partition0 container\n \n![](images/26-output-partition0.png)\n\n**_7.**\tClose the Web Browser window\n\nYou have successfully built run the DefaultApplication that was transformed using the IBM Mono2Micro. \n\nThe converted application has also been deployed locally in Docker containers running OpenLiberty Server, which is ideally suited for Java based microservices and cloud deployments. \n\nNow that you have seen the transformed application in action, it is time to use Mono2Micro and perform the steps that produced the transformed microservices. \n\n### **Part 2**\n#### **7.3. Use Mono2Micro to analyze the Java EE monolith application and recommend microservices partitions**\n\nObjectives\n  *\tLearn how to use the AI-driven Mono2Micro tools to analyze a Java EE monolith and to recommend the different ways it can be partitioned into microservices\n  *\tLearn how to use Mono2Micro tools to further customize the partitioning recommendations \n\nIn this part of the lab, you first pull the Mono2Micro tools from Dockerhub, then you :\n  1).\tRun Mono2Microâ€™s Bluejay tool to analyze the Java source code, instrument it, and produce the analysis files that will be used as input to the Mono2Microâ€™s AI engine. \n  2).\tUse Mono2Microâ€™s Flicker tool to gather time stamps and use case data as you run test cases against the instrumented version of the monolith application. \n  3).\tUse Mono2Microâ€™s Oriole analyzer tool (AIPL) to produce the initial microservices recommendations. \n  4).\tUse Mono2Microâ€™s UI tool to visualize the microservice recommendations and modify the initial recommendations to further customize the microservice recommendations.\n\n![](images/27-m2m-flow.png)\n\n**_1.** Pull the Mono2Micro Images from Dockerhub\n\nAll the four Mono2Micro container images are available from Dockerhub\n  * https://hub.docker.com/r/ibmcom/mono2micro-bluejay\n  * https://hub.docker.com/r/ibmcom/mono2micro-aipl\n  * https://hub.docker.com/r/ibmcom/mono2micro-ui \n  * https://hub.docker.com/r/ibmcom/mono2micro-cardinal\n\n**a.** Download all the Mono2Micro images by issuing the docker pull commands: \n\n```\ndocker pull ibmcom/mono2micro-bluejay\n\ndocker pull ibmcom/mono2micro-aipl\n\ndocker pull ibmcom/mono2micro-ui\n\ndocker pull ibmcom/mono2micro-cardinal\n```\n\n**b.**\tList the docker images. You should see the four images listed\n\n```\ndocker images | grep ibmcom\n```\n\n![](images/28-docker-images.png)\n\n**_2.** Use Flicker and Mono2Micro Bluejay\n\nFor this lab, we have provided the Flicker java program and its required open-source jars in the GitHub repository, that you cloned earlier in the lab. You use Flicker later in the lab, when you run the test case for the application. \n\nPrerequisites for using Flicker: \n  * Flicker requires Java 1.8 or higher for execution.\n  * Flicker also requires two open source jars, and are included in the GitHub repository for this lab: \n  *\tcommons-net-3.6.jar\n  *\tjson-simple-1.1.jar \n\nThe first step in using Mono2Micro is to prepare the monolithâ€™s Java source code for static and dynamic analysis. Mono2Micro Bluejay tool is used to analyze the application source code, instrument it, and produce the analysis in two .json files.\n\nFor the **DefaultApplication** used in this lab, the complete set of source code for the monolith application is already available in a single directory structure cloned from GitHub. \n\nFor this lab, the monolith source files tree can then be found in **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith**  directory. \n\nLetâ€™s begin with the static data collection phase by running Mono2Microâ€™s Bluejay tool to analyze the Java source code, instrument it, and produce the analysis in two .json files. \n\n**a.** Run the Bluejay analysis using the following commands:\n\n```\ncd /home/ibmadmin/m2m-ws-sample\n\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/:/var/application ibmcom/mono2micro-bluejay /var/application/defaultapplication/monolith out\n```\n    \n![](images/29-docker-run.png)\n    \nNote: The command displays the directory where the output files were generated, as illustrated below.\n\nIn this example: /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\n**b.**\tReview the output from Bluejay: \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\nls -al\n```\n\n![](images/30-ls-al.png)\n\nBluejay creates a mirror copy of the input source directory in its parent directory with a **-klu** extension where all the Java files within the entire directory tree will be instrumented to log entry and exit times in each method.  \n\nIn addition to instrumenting the source, Bluejay creates two .json files in the in the monolith-klu directory: \n  *\trefTable.json\n  *\tsymTable.json\n\nThese json file capture various details and metadata about each Java class such as:   \n  *\tmethod signatures\n  *\tclass variables and types\n  *\tclass containment dependencies (when one classes uses another class as a instance variable type, or method return/argument type)\n  *\tclass inheritance\n  *\tpackage dependencies\n  *\tsource file locations\n  *\tetc. \n\nThis static analysis therefore gathers a detailed overview of the Java code in the monolith, for use by Mono2Microâ€™s AI analyzer tool to come up with recommendations on how to partition the monolith application. \n\nFurthermore, this information is also used by Mono2Microâ€™s code generation tool to generate the foundation and plumbing code for implementing each partition as microservices.\n\n**c.**\tLook at an example of the instrumentation in the monolith code.  \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultWebApplication/src/main/java\n\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultWebApplication/src/main/java/HitCount.java\n```\n\nAs illustrated below, you will find **System.out.printlnâ€¦** statements for the entry and exit of each method in the classes. \n\nThis trace data captures the Thread ID and Timestamp during the test case execution flow, which you will perform later in the lab. \n\n![](images/31-hitcount-java.png)\n\n**d.**\tClose the gedit editor window\n\n**e.**\tChange the permissions on monolith-klu directory, so that it can be updated by the current user.  \n\nBluejay runs in a Docker container. By default, Docker runs as **root** user, and therefore all the files in the instrumented monolith directory are owned by root. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication\n\nsudo chmod -R 777 ./monolith-klu\n```\n    \nWhen prompted for a password, enter: **passw0rd**   (That is a numeric zero in passw0rd)\n  \nThe next step is to run test cases against the instrumented monolith application to capture runtime data for analysis. \n\n**_3.** Run test cases using the instrumented monolith for Runtime data analysis\n\nNow you are ready to proceed to the next phase of data collection from the monolith application. This is a crucial phase where both the quantity and quality of the data gathered will impact the quality and usefulness of the partitioning recommendations from Mono2Microâ€™s AI analyzer tool. \n\nThe key concept here is to run as much user scenarios as possible in the running instrumented monolith application, exercising as much of the codebase as possible.  \n\nThese user scenarios (or business use cases if you will), should be typical user threads through the application, related to various functionality that the application provides. More akin to functional verification testcases or larger green thread testcases, and less so unit testcases.\n\nIn the DefaultApplicationâ€™s case, these scenarios are very simple, which is partially why we selected this application for the lab. For real applications, your test cases could be quite extensive in order to achieve maximum code coverage in the tests.  \n\nTest cases for DefaultApplication:\n  *\tRun the Snoop action\n  *\tRun the HitCount action\n\n**_4.** Deploy the instrumented application to Liberty for testing\n\nThe test cases (use cases) that you will run must be executed on the instrumented code base, which is in the **monolith-klu** directory. \n\nAs such, the instrumented code needs to be compiled, new deployment binaries generated, and redeployed to the local Liberty server that you will use to run the test cases. \n\nThe DefaultApplication is a Maven based project. The instrumented application can easily be rebuilt using Maven CLI. Maven version 3.6.3 has been verified to work in this lab. \n\n**a.**\tBuild and package the instrumented version of the DefaultApplication  \n\nThe top-level pom.xml that is used to build and package the application is in the **monolith-klu** folder. You will change to that directory and run the Maven build. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\nmvn clean install\n```\n\nMaven should have successfully built the application and generated the binary artifacts (EAR, WAR), and placed them in the Liberty Server **apps** folder.  Now the application is ready to run test cases.   \n\n![](images/32-mvn-install.png)\n  \n**b.**\tRun the scripts below to Start the Liberty server and check that the server is in the running state\n\nAs a convenience, we have provided simple scripts for you to use to start and stop the Liberty server, as well as check the status of the server. \n\n```\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/startServer.sh\n\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/serverStatus.sh\n```\n    \n![](images/33-server-running.png)\n    \nTip: The Liberty server is in the folder: **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/usr/servers/DefaultApplicationServer**.\n\n**c.**\tOpen a Web Browser and launch the **DefaultApplication** URL: http://localhost:9080\n  \nThe main HTML page will be displayed. \n\nNotice the application only has two main features: \n  * Snoop\n  *\tHit Count\n  \n![](images/34-defaultapp-9080.png)\n\n**_5.** Run the test cases for the DefaultApplication\n\nSince this is a simple application, you will run the test cases manually using the applications web UI. There are only two use cases for this simple application.: Snoop and Hit Count. \n\nAs these use cases are run on the instrumented monolith application, you will use Mono2Microâ€™s Flicker tool to record use case labels and the start and stop times of when that use case or scenario was run.  \n\nThe Flicker tool essentially acts like a stopwatch to record use cases. \n\nThe labels provided to Flicker for each use case should be meaningful as this will come into play later when viewing Mono2Microâ€™s AI analysis where the classes and flow within the code is associated with the use case labels. \n\nFlicker is a simple Java based tool that prompts the user for the use case label, and then records the start time. Then prompts again for the **stop** command after the user finishes running that scenario on the monolith.\n  \n**_5.1.**\tFirst, start the Flicker tool, using the command below in a new Terminal window:\n\n```\ncd /home/ibmadmin/m2m-ws-sample/Flicker\n\njava -cp commons-net-3.6.jar:json-simple-1.1.jar:. Flicker -no_ntp\n```\n\nNotice that Flicker is just waiting for you to provide a **Label** or name of the test case to run. You will do that in the next step.  \n\n![](images/35-flicker-lable.png)\n  \n**_5.2.**\tRun the **Snoop** test case. Follow the steps below to run the Snoop test case.\n\n**a.** In the web browser, go to http://localhost:9080/\n\n**b.**\tFrom Flicker, provide the label named **snoop** and press **ENTER**. This starts Flickerâ€™s stopwatch for the snoop test case. \n \n![](images/36-flicker-snoop.png)\n\n**c.**\tFrom the Web Browser, click on the **Snoop Servlet** link in the DefaultApplication HTML page. Snoop requires basic authentication. If prompted for credentials, enter the following username and password:\n\nUsername: **user1**\n\nPassword: **change1me**   (that is the number 1 in the password).  \n \n![](images/37-snoop-servlet-link.png)\n\n**d.**\tRun snoop multiple times: Just click the Browsers **Reload Page** button. \n**e.**\tWhen finished, click on the Browsers **Back** button   to return to the applications main HTML page. \n**f.**\tIn Flicker, enter **STOP**, to stop Flickers stopwatch for the test case\n\nNote: **STOP** must be in upper-case and is Case Sensitive. \n  \nNotice Flicker has recorded the START and STOP times for the **snoop** test case. These timestamps correspond with the timestamps in the Liberty log file, from the instrumented version of the DefaultApplication running in Liberty. \n  \n![](images/38-flicker-stop.png)\n  \n**_5.3.**\tRun the Hit Count test case. Running the Hit Count test case requires the same basic step as Snoop, but has a few more options to test in the application: \n  \n**a.**\tIn Flicker, provide the label named **hitcount** which will start Flickerâ€™s stopwatch for the snoop test case. \n \n![](images/39-flicker-hitcount.png)\n  \n**b.**\tFrom the Web Browser, click on the Hit Count link in the DefaultApplication HTML page. \n\nHit count displays a JSP page with several options that demonstrate a variety of methods to increment a counter, while maintaining state.  \n\n**c.**\tRun hitcount, choosing each of the following options from the application in the web browser: \n\t\t  \n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\n**d.**\tRun hitcount, choosing the following option from the application in the web browser: ** Enterprise Java Bean (JPA)**.\n\nWhen choosing the EJB option, you also must select one of the following Transaction Types, radio buttons:\n  * None\n  * Commit\n  * Rollback\n \nThis action invokes an EJB and uses JPA to persist the increment state to a Derby database. \n\n![](images/40-hit-count-demo.png)\n    \n**e.**\tYou can run HitCount multiple times, choosing different **Transaction Type** options. \n      \n**f.**\tIn Flicker, enter **STOP**, to stop Flickers stopwatch for the test case\n\nNote: **STOP** must be in upper-case and is Case Sensitive. \n\nFlicker has now captured the START and STOP timestamps for the use cases, which corresponds to the timestamps recorded in the Liberty log file from the instrumented version of the DefaultApplication.\n  \n![](images/41-flicker-stop.png)\n    \n**g.**\tIn Flicker, enter **Exit**, to quit Flicker    (Case sensitive, Capital E)\n\n**_5.4.**\tRun the script below to Stop the Liberty server. As a convenience, we have provided simple scripts for you to use to start and stop the Liberty server, as well as check the status of the server. \n\n```\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/stopServer.sh\n````\n\n![](images/42-stopping-server.png)\n\n**_6.** Review the output from Flicker and the Liberty Log file based on the test cases\n\nAfter exiting the Flicker tool, it produces a context json file that captures the use case labels and their start/stop times. The context json files are generated in the same directory where Flicker ran. \n\nThis context json file will be used as input to the AI engine in Mono2Micro for shaping the recommendations for microservices partitioning. \n\n**_6.1** Review the output from Flicker and Liberty log file based on the test cases you executed\n\nTake a quick look at the context file that Flicker generated for the snoop and hit count test cases\n\n**a.**\tView the context json file. \n\nThe name of the context json file contains timestamp in its name. So view the files in the Flicker directory, and then view the **context*.json** file. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/Flicker\n\nls *.json\n\ncat context*.json\n```\n\nNotice the two test cases were recorded, along with the start and stop timestamps for each testcase. \n\n![](images/43-cat-json.png)\n\n**b.**\tView the Liberty log file to ensure the log contains the trace statements from the instrumented version of the application.  \n\n```\ncat /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/usr/servers/DefaultApplicationServer/logs/messages.log\n```\n\nAs illustrated in the screenshot below, the Liberty server log file (messages.log) will include trace data that captures the entry and exit of each Java method called, along with the timestamp of the invocation. \n    \nIf the log file does NOT contain trace statements for Snoop and Hit count as illustrated below, it is likely that the instrumented version of the application was not deployed to the Liberty server. \n\nDo not worry, we have captured a known good log file and Flicker context json file that can be used to continue the lab, without having to go back and redo previous steps.  \n\n![](images/44-message-log.png)\n    \nTip: It is critical that the server log files DO NOT get overwritten during the execution of the test cases. \n\nSystem Administrators configure limits for how much data is logged and kept. \n    \nThey do this by configuring a MAX size for the log files, and the MAX number of log files to keep. If or when these maximum thresholds are reached, Liberty will write over the messages.log file, resulting in the timestamps from our test cases to be out of whack. \n    \nTherefore, it is critical to ensure proper sizing of these logging thresholds to ensure log files are not overwritten when running the test cases.  \n\nSince the tests in this lab are short and simple, there will not be an issue. But something to look out for when running larger test suites. \n\n**_7.** Recap of the data has been collected for the monolith \n\nLetâ€™s review the data that has been collected on the monolith:\n  *\tBluejay generated two table json files containing specific information about the java classes and their relationships via static analysis of the code: \n  *\trefTable.json\n    *\tsymTable.json\n    *\tFlicker generated one or more context json files that contains use case names/labels and their start and stop times\n    *\tAll the standard console output/error log files captured on the application server side as the use cases were being run on the instrumented application \n\nWith these three sets of data, Mono2Micro can now correlate what exact Java classes and methods were executed during the start and stop times of each use case, and thereby associate the observed flow of code within the application to a use case. \n\n![](images/45-m2m-flow.png)\n  \nLetâ€™s proceed to the next phase of using Mono2Micro, which is to run the AI analyzer tool against this data.\n\n**_8.** Running Mono2Microâ€™s AI Analyzer for Application Partitioning Recommendations\n\nMono2Microâ€™s AIPL tool is the analyzer that uses unsupervised machine learning AI techniques to analyze the three sets of data collected on a monolith applicated as done in the previous section.  \n\nOnce you have completed the executing all the test scenarios, you should have the following categories of data collected:\n  * symTable.json\n  * refTable.json\n  * one or more json files generated by Flicker, and\n  * one or more log files containing the runtime traces\n\nPrepare the input directories for running the AIPL tool \n\nTo prepare for the analysis, the input directories and an optional config.ini file need to be gathered and placed (copied) into a common folder structure before running the AIPL tool.  \n\nFor this lab, the input directories have been placed into the following directory structure for you. \n\nThe /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/ directory contains the subdirectories within which the data files are placed:\n  \n**contexts/** - One or more context .json files generated while running the Flicker tool alongside the use case runs\n    \n**logs/** - One or more console logs from the application server as the instrumented monolith was run through the various use cases\n  \n**tables/** - The two table .json files generated by the Bluejay tool \n  \n**config.ini** -  Optional file to configure various parameters for the analysis tool. If one doesnâ€™t exist, AIPL generates one for you with default values. \n \n![](images/46-ls-r.png)\n  \n**_8.1.** Run the AIPL tool to generate the microservices recommendations. \n\nOnce you have completed the data collection process for the Java monolith under consideration, you can feed the data to the AIPL tool to generate microservices recommendations.\n\n**a.**\tChange directory to application-data directory\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data\n```\n\n**b.**\tRun the AIPL tool, using the following command:\n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data:/var/application ibmcom/mono2micro-aipl\n```\n\n![](images/47-docker-run.png)\n    \nWhen the AIPL tool finishes its analysis, it will generate an application partitioning recommendations graph .json file, various reports, and other output files in the mono2micro/mono2micro-output/ subdirectory within the parent directory of the input subdirectories.\n    \nNext. Explore some of the notable files and reports generated by Mono2Micro. \n    \nListed here are some of the notable files that were generated from the AIPL tool\n\n**Cardinal-Report.html** is a detailed report of all the application partitions, their member classes, outward facing classes, etc\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/Cardinal-Report.html**\n\n**Oriole-Report.html** is a summary report of all the application partitions and their associated business use cases\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/Oriole-Report.html**\n\n**final_graph.json** is the full set of application partition recommendations (natural seams and business logic) and associated details, viewable in the Mono2Micro UI\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/oriole/final_graph.json**\n\n**cardinal/** is a folder that contains a complete set of input files (based on the partitioning) for the next and last stage of the Mono2Micro pipeline, running the code generator\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/cardinal/**\n\n**c.**\tContinue to the next section. You will explore the generated reports later in the lab. \n\n**_8.2**   Use the mono2micro UI to view and manipulate the partitioning recommendations generated from the AIPL tool \n\nLetâ€™s now take a look at the partitioning recommendations Mono2Micro generated by loading the final_graph.json in the graph UI. \n\n**a.**\tLaunch the Mono2Micro UI using the following command:\n\n```\ndocker run -d -p 3000:3000 --name=m2mgui ibmcom/mono2micro-ui\n```\n\n**b.**\tFrom a web browser, navigate to http://localhost:3000/\n \n![](images/48-m2m-ui.png)\n\n**c.**\tLoad the final_graph.json file in the mono2micro UI\n  \n**d.**\tFrom the UI, click the **Drop or Add File** link \n\n**e.**\tFrom the **File Upload** dialog window, navigate to the following final_graph.json file: **Home>ibmadmin>m2m-ws-sample>defaultapplication>mono2micro-analysis>oriole>final_graph.json**.\n\n**f.**\tClick the **Open** button on the File Upload dialog, to load the file into the UI.\n\n![](images/49-m2m-load-json.png)\n \n**g.**\tFrom the UI, click the **X** to SKIP the tour, and proceed to the results\n \n![](images/50-m2m-ui-close-tour.png)\n  \nAs illustrated below, the UI displays the initial recommendations for partitioning the application into microservices. From the UI, you can explore the partition recommendations \n    \n![](images/51-m2m-ui-final-graph.png)\n    \nThe initial partitioning recommendations is a starting point and generated taking into consideration based on the business logic and natural seams that were discovered during the analysis. \n\nAt the time of this writing, there is a known issue in Mono2Micro where in certain cases a class is placed in the Unobserved part despite use cases being run where its use is captured in the logs. This affects Snoop Servlet for this application. However, in the lab, you will slightly customize the partition recommendations to suit our goals, and at that time, you will move the Snoop class into an appropriate partition. This will provide an opportunity to see how easy it is to customize the recommendations to tailor them to exactly suit your desired end state.  \n\nThe Default Application contains two major Java components in the application: **Snoop Servlet** and **HitCount application**.\n\nIn addition to the Java components, the application also contains HTML, JSP, and other web resources. \n\nThe goal of this lab is to split the Default Application monolith into separate microservices, such that the (Front-end) Web components run as a microservice, and the (back-end) EJB and data layer run as a separate microservice.  \n\nIn this exercise, we will ensure that the Web components (Servlets, HTML, JSP, etc) will be in the (front-end) web partition, and the (back-end) HitCountâ€™s increment action Java / EJB components run in a separate partition. \n  \n**h.**\tEnsure the view in the UI to display partitioning recommendations are set to **Business Logic**. \n \n![](images/52-m2m-ui-business-logic.png)\n    \nAlternatively, you can use the pull-down selector to view the recommendations based on **Natural Seems**, Custom Views, or **Data Dependencies**. \n  *\tBusiness logic partitioning is based on the runtime calls from the test cases\n  *\tNatural Seems partitioning is based on the runtime calls and class dependencies.  For example, an Object of class A holds a reference to an object of class B as a variable\n\nFor natural seams-based partitioning, Mono2Micro creates partitions while avoiding inter-partition containment data dependencies â€“ containment data dependencies between classes belonging to different partitions\n  *\tCustom: Customize how your classes are grouped. Start from either the Business logic view or the Natural seams view.\n\n**i.**\tIf you explored other views, return to the **Business Logic** view.  \n  \n![](images/53-m2m-ui-business-logic-2.png)\n\nFrom the Business Logic view, notice that there are three partitions created, and a special partition for **Unobserved** classes. \n  *\tThe Numeric value in the partitions reflects the number of Java classes inside of the partition\n  *\tThe Lines between partitions indicates where classes from one partition make calls to classes in a different partition\n  *\tThe Unobserved partition is a group of classes that were analyzed but were not found to be included in any of the use case test that were executed earlier. This could be due to dead code, or incomplete set of test cases for adequate code coverage. \n\nNOTE: And as noted earlier, there is a bug in the Beta version of Mono2Micro that caused SnoopServlet to be unobserved, even though it was included in a test case.  \n\n**j.**\tExplore the Java classes in partition0, partition1, and partition by double-clicking on each of the partitions to display the classes in each partition\n\n![](images/54-m2m-ui-partitions.png)\n  \n  * Partiton0 contains two classes (Increment and IncrementSSB) which are EJB components that are used to persist increment data to a backend Derby database. \n  * The **Increment** EJB classis called from the **IncrementAction** Java class that is in partition2.  \n  * Partition1 contains the HitCount Servlet, which then calls the IncrementAction Java class in Partition2. \n\n**k.**\tExplore the Java classes in the **Unobserved** group by double-clicking on the Unobserved group to display the classes. This is a group of classes that Mono2Micro analyzed but were not included in any of the test cases. \n\n![](images/55-m2m-ui-unobserved.png)\n  \n  *\tEndpointIT is a class that exists in the Junit Tests in the Java project. We did not run the Junit tests as part of the test cases. Therefore, it is expected that this class is not included in any of the partitions. \n  *\tSnoopServlet is a core class that was included in the snoop test case and should have been included in partition1 along with the HitCount Servlet. This is a known bug in the Mono2Micro beta at the time of this writing. You will move this class to an appropriate partition in the next section of the lab, when we customize the partition recommendations from the Mono2Micro UI. \n\nThe initial partitioning recommendations are a starting point and generated taking into consideration based on the business logic and natural seams that were discovered during the analysis.\n\nIn this lab, you slightly customize the partition recommendations to suit our desired goals while providing an opportunity to see how easy it is to customize the recommendations to tailor them to exactly suit your desired end state.  \n\n**_8.3.** Customizing & Adjusting Partitions\n\nIn order to refine the recommended business logic partitions, letâ€™s consider the classes in partiton1 and the Unobserved group. In these partitions, the classes were servlet classes, as well as a Junit test class. \n\nGiven that the DefaultApplication  monolith has a web based front-end and UI, letâ€™s use one single partition to house all the front-end code for the application, which then would include all html/jsp/etc files, and the Java servlet classes which are referred to by the html file. \n \t\nThe important point to note here is that Java servlets need to be running on the *same* application server instance that serves up the html files referring to the servlets\n\nThe goal of this lab is to split the Default Application monolith into separate microservices such that: \n  *\tThe (Front-end) Web components run as a microservice\n  *\tThe (back-end) EJB and data layer run as a separate microservice\n\nThe partition recommendations from Mono2Micro is a good first step toward partitioning the application for microservices. \n\nThe illustration below shows our desired final state of the partitioning, which will then be used as the basis for the microservice code generation later in the lab. \n\nIn this section of the lab, you use the Mono2Micro UI and tweak the graph to the desired state. \n \n![](images/56-m2m-ui-web-partition0.png)\n  \nTweaking the business logic recommendations is straight forward using the UI, and includes these basic steps, which you will do next: \n  *\tRename partition1 to web. This is not required but illustrates the capability to create partitions with names that make sense. This is useful during the code generation phase. \n  *\tMove SnoopServlet class to the web partition. All the Servlets and other front-end components should be here. \n  *\tMove the IncrementAction class to partition0. This class will become the new REST service class during the code generation phase\n\n**_8.3.1**    Customize the graph\n\nThis section shows how to create a custom view for editing the partitioning recommendations\n  \n**a.**\tTo create a custom view, first select Custom View from the Graph view selection pull-down menu\n \n![](images/57-m2m-ui-custom-view.png)\n  \n**b.**\tSelect Business Logic view as the starting point for the custom view. The click the Start button. \n \n![](images/58-m2m-ui-business-logic-3.png)\n  \n**c.**\tToggle the Edit graph to the **ON** position to allow editing of the graph\n \n![](images/59-m2m-ui-edit-graph.png)\n  \n**d.**\tDouble-click on each of the partitions to view the classes within the partitions and Unobserved group. \n \n![](images/60-m2m-ui-view-classes.png)\n  \n**e.**\tRename **partition1** to **web** by clicking on partition1 that includes the HitCount class\n\n**f.**\tClick on the pencil icon  to rename the partition.  \n \n![](images/61-m2m-ui-rename-partition.png)\n  \n**g.**\tType **web** as the new partition name. Then press **ENTER** key to finalize the name change.\n \n![](images/62-m2m-ui-name-changed.png)\n  \nThe partition has been renamed to **web**.\n\n![](images/63-m2m-ui-name-web.png)\n \n**h.**\tMove the SnoopServlet class to the **web** partition by dragging and dropping the SnoopServlet class from the Unobserved partition to the web partition\n \n![](images/64-m2m-ui-drag-drop.png)\n    \nThe **SnoopServlet** is now located in the web partition.\n  \n![](images/65-m2m-ui-snoopservlet-moved.png)\n    \n**i.**\tMove the **IncrementAction** class from **partition2** to **partition0** by dragging **IncrementAction** class from partition2 to partition0\n \n![](images/66-m2m-ui-drag-drop-2.png)\n  \nThe **IncrementAction** class is now located in partition0\n \n![](images/67-m2m-ui-incrementaction-moved.png)\n  \n**l.**\tClick on the **Save** icon to save the updated custom view. The customized final_graph.json file is saved to the Downloads folder. \n \n![](images/68-m2m-ui-save-changes.png)\n  \n**_8.4** Regenerate the partition recommendations by rerunning AIPL against the customized graph\n\nTo generate the new microservice recommendations and the relevant reports for a modified graph you must execute the AIPL tool with the regen_p option. \n\nAdditionally, the AIPL tool must reference the customized version of the final_graph.json file. To prepare to run the AIPL tool again, you must first do a couple of manual steps: 1).\tMove the customized final_graph.json file from **Downloads** folder to a known location by Mono2Micro. 2).\tRename the customized **final_graph.json** file to a name that makes it obvious this is our customized graph and not the original. 3). \tModify the Mono2Micro **config.ini** file to reference the name and location of the customized graph file. \n\n**_8.4.1.**\tCopy the customized final_graph.json file from users **Downloads** folder to a known location by Mono2Microâ€™s AIPL tool, and name it custom_graph.json\n\nBy default, the AIPL tool will look in the root directory of the application-data folder where the contexts, logs, and tables are located. \n\nThis is the directory structure that was setup for the initial run of the AIPL tool earlier in the lab. All you will do now I copy the final_graph.json file to this folder location where it will be discovered by the AIPL tool. \n    \nRun the following commands to copy the file, change to the target directory, and list the files and ensure the custom_graph.json has been copied to the desired directory\n\n```\ncp /home/ibmadmin/Downloads/final_graph.json /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/custom_graph.json \n\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data\n\nls -l \n```\n  \n![](images/69-ls.png)\n\n**_8.4.2.**\tFrom the same folder as the custom-graph.json, modify the permissions for config.ini so that we have write permissions\n\n```\nsudo chmod 777 ./config.ini \n```\n  \nWhen prompted, enter the sudo password for ibmadmin:  **passw0rd**\n\n**_8.4.3.**\tEdit the config.ini file to reference the new custom_graph.json file to be used for regenerating the partition recommendations. (Use any editor available)\n\n```\ngedit ./config.ini\n```\n\n**a.** Modify the config.ini by changing the value for the **UserModifiedGraph** property to **custom_graph.json**.\n\n**b.**\tSave and Close the config.ini file.\n \n![](images/70-save-config-ini.png)\n\n**_8.4.4.**\tRerun the AIPL tool with the regen_p option to generate the partitioning recommendations based on the updated graph file. \n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data:/var/application ibmcom/mono2micro-aipl regen_p\n``` \n\n![](images/71-docker-run.png)\n\n**_8.4.5.** Explore the generated Cardinal report based on the customized graph and regenerated recommendations from AIPL\n\nThe AIPL created a new folder based on the user modified graph in the following directory: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified**\n\n**a.**\tList the files / folders of the generated directory.\n\n```\nls -l  /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified\n```\n  \n![](images/72-ls-l.png)\n\n**b.**\tView the generated Cardinal report to verify the partitions and exposed services are defined as expected. \n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified\n\nfirefox ./Cardinal-Report-Modified.html\n```\n\nThe Cardinal-Report provides a deep analysis of all the inter-partition invocations, the types of all the non-primitive parameters passed to partitions during their invocations, and foreign class references within a partition. \n\nClasses are foreign to a partition if they are defined in another partition.\n\n![](images/73-m2m-deep-partition-analysis.png)\n  \n**c.**\tReview the partition0 Partition.\n\nPartition0 should include three Member classes:   \n  *\tIncrement\n  *\tIncrementAction\n  *\tIncrementSSB\n\nPartition0 should have one External Facing class:\n  * IncrementAction\n\nMono2Micro detected that there are classes outside of partition0 that call methods on the IncrementAction Class. \n      \nDuring the code generation phase of Mono2Micro, the Cardinal tool will generate a REST service interface for the IncrementAction class, so that other microservices can make the remote method calls in a loosely coupled Microservices architecture. \n  \n![](images/74-m2m-partition0.png)\n    \n**d.**\tReview the web Partition\n\nThe web partition should include two Member classes:\n  *\tHitCount\n  *\tSnoopServlet\n\nThe web partition invokes one class method residing outside of this partition:\n  *\tOutside partition: partition0\n  *\tClass Name IncrementAction\n  *\tMethods:  getTheValue and increment\n\nMono2Micro detected that classes in the web partition call methods in partition0.  \n\nDuring the code generation phase of Mono2Micro, the Cardinal tool will generate a Proxy for the class to call the REST service interface in partition0. \n \n![](images/75-m2m-web-partition.png)\n\n### **Part 3**\n#### **7.4 Generating Initial Microservices Foundation Code**\n\n**Objectives**\n  *\tLearn how to use Mono2Micro tools to generate a bulk of the foundation microservices code, while allowing the monolith Java classes to stay completely as-is without any rewriting \n\nIn this part of the lab, you: \n  * Use Cardinal to generate the microservices plumbing code for the two microservices (front-end and back-end)\n  * Refactor the transformed Microservices\n    * Move the static and non-Java artifacts from the monolith application into the individual microservices\n    *\tRefactor the minimal set of artifacts so that the transformed microservices will compile and run in OpenLiberty server in Docker containers.\n\n![](images/76-m2m-flow.png)\n \nAfter going through the microservice recommendations generated by the mono2micro-aipl container, you can use Mono2Micro to automatically generate API services and related code to realize the microservice recommendations. \n\nThis is accomplished by executing the Cardinal component available as the mono2micro-cardinal container.\n\nCardinal automatically performs three crucial tasks for the architects and developers in the refactoring endeavor of realizing partitions (microservices recommendations) as microservices. \n\nThe tasks performed by Cardinal can be listed as follows: \n  *\tIt creates transformational wrappings to turn partition methods into microservices APIs\n  *\tIt provides an optimized distributed object management, garbage collection, and remote local reference translations like the Java remote method invocation mechanism.\n  *\tIt provides pin-pointed guidance on what the developers should check and manually readjust or tweak code in the generated microservices.\n\n**7.4.1.** Run the Cardinal code generation tool\n\nNow, letâ€™s run the Cardinal code generation tool to generate the plumbing code for the microservices. \n\nThe cardinal code generation tool requires the following input artifacts and is referenced in the cardinal command for proper execution: \n  *\tThe parent folder of the original DefaultApplication monolith application: **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith**.  \n  *\tThe cardinal folder from the mono2micro-user-modified directory that was generated by the AIPL tool using the regen_p option: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\nFor the lab, you reference a saved version of the cardinal folder when running the cardinal tool. This is just to ensure a known good dataset is used for the code generation: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\nIf you would rather use the cardinal folder that was generated during the lab, use: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified/cardinal**.\n\n**_1.**\tRun Cardinal code generation tool using the following command: \n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication:/var/application ibmcom/mono2micro-cardinal /var/application/monolith /var/application/mono2micro-analysis-custom/cardinal\n```\n\t\n![](images/77-docker-run.png)\n\n**7.4.2.** Examine the Cardinal Summary report to understand what Cardinal generated for each partition\n\nUpon completion of running cardinal code generation tool, the plumbing code for microservices are generated, along with several reports that provide summary and details of the Java source files that were generated. \n\n**_1.**\tExamine the **CardinalFileSummary.txt** file. \n\nThis file provides a summary of all the files that were generated or modified during the code generation. \n\nThe location of the cardinal reports is in a folder named **cadinal-codegen**. The path to this folder is relative to the **cardinal** input folder specified on the cardinal command line. \n\nIn this case, the cardinal-codegen folder and associated reports are generated here: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified/cardinal**.\n  \n**a.**\tOpen the CardinalFileSummary.txt file using an available editor\n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal/cardinal-codegen\n\ngedit CardinalFileSummary.txt\n```\n\n**b.**\tExamine the web partition summary in the **CardinalFileSummary.txt** file \n \n![](images/78-cardinal-files-summary.png)\n  \nThis section of the report shows the classes contained in the web partition. The report further denotes the types of classes that are in the partition.\n  *\tProxy classes are created for calling out to a class to an outside partition via REST API. In this case, the HitCount Servlet in the web partition calls the IncrementAction REST Service class in partition0. \n  *\tService classes are generated REST Service interface classes. A service class is generated for each Java class that is receiving proxied requests from one partition to another via REST API. \n  *\tOriginal classes are the classes that already existed in the monolith and will remain in the web partition. In this case, the SnoopServlet and HitCount servlet are kept as original. \n  *\tDummy classes are classes that were in the monolith but will now exist in a different partition. The Dummy classes throw an exception that is defined in the Utility classes that are created in every partition. \n  *\tUtility classes are created to handle the plumbing such as serialization, exceptions, logging, and interfaces for the new microservices.  \n\n**_2.**\tScroll down and examine the **partition0** partition summary in the **CardinalFileSummary.txt** file \n \n![](images/79-cardinal-files-summary-2.png)\n  \nThis section of the report shows the classes contained in the partition0 partition. The report further denotes the types of classes that are in the partition.\n  *\tProxy classes are created for calling out to a class to an outside partition via REST API. \n  *\tService class, IncrementActionService is created based on the web partition calling to the IncrementService in partition1 via REST API. \n  *\tOriginal classes are the classes that already existed in the monolith and will remain in the web partition. In this case, the Increment, IncrementAction, and IncrementSSB classes will remain in the partition0. \n  *\tDummy classes are classes that were in the monolith but will now exist in a different partition. The Dummy classes throw an exception that is defined in the Utility classes that are created in every partition. The SnoopServlet and HitCount Servlet will be in the web partition.\n  *\tUtility classes are created to handle the plumbing such as serialization, exceptions, logging, and interfaces for the new microservices.  \n\n**_3.**\tClose the editor for the CardinalFileSummary.txt file \n\n**7.4.3.** Examine the Java code that was generated by Cardinal\n\nCardinal generates the Java source files in separate folders for each partition and are named according to their respective partitions.  \n\nThe location of the Java source files is in a folder named **-partiton0** and ***-web**. \n\nThe actual folder name is dependent upon the input paths specified on when running the cardinal command. In our case, the actual folder names are: \n  *\tmonolith-web\n  *\tmonolith-partition0\n\nThe root folder for the generated source files is also dependent on the input paths specified when running the cardinal tool.  \n\nIn this case, the monolith-web and monolith-partitio0 folders are generated here: **/home/ibmadmin/m2m-ws-sample/defaultapplication**.\n\nFor the purpose of this lab, it is not necessary to understand the details of all the code that Cardinal generates. However, we strongly recommend learning this before using Mono2Micro with a production application. See APPENDIX A:  Examine the Java Code generated by Mono2Micro provides a detailed look at these generated files.\n\n**7.4.4.** Refactoring Non-Java Parts of Monolith, Further Code Changes, and Deploying Final Partitions as Microservices\n\nAfter Mono2Micro generates the initial microservices plumbing code and places that along with the monolith classes into each partition, the foundations of the microservices are now there. \n\nThat is, each partition is meant to run as a microservice, deployed on an application server (such as WebSphere Liberty) where the monolith classesâ€™ public methods are served up as REST API. Each partition is effectively then a mini version of the original monolith, its folder structure mirroring the original monolith folder and module structure. \n\nIn order to build and run each partition, more than just the Java code is needed of course.  And here is when a key question is usually raised: What exactly does one do with the non-Java parts of the monolith with respect to each partition, and how, in order to facilitate the final goal of running all partitions as microservices?\n\n**One Approach**\n\nOne approach that you will follow for the DefaultApplication example and highly recommend for most Java applications is as follows: \n  *\tCopy *all* the non-Java files in the monolith (i.e. the build config files such mavenâ€™s pom.xml or gradle files, server config files such as WebSphereâ€™s server.xml, Java EE meta-data and deployment descriptors such as application.xml, web.xml, ejb-jar.xml, persistence.xml etc) to *every* partition, following the same directory structure which will partially already exist in each partition. \n  *\tStarting with that as a base, the aim then is to pare down and incrementally reduce the content of all these files (based on knowledge of what functionality each partition entails, and/or through an iterative compile-run-debug process), ending up with just the needed content in each partition. \n  *\tAfter this is done, each partition will indeed be a mini subset of the original monolith and working together with all the other running partitions and finally become microservices that provide the exact same functionality as the original monolith.\n\nAs each partition is now becoming a separate microservice project and will be developed and deployed independent of the other microservices, ideally, you would create Java projects in your favorite IDE and follow these basic steps for new microservice projects: \n  *\tCreate a Java EE web project for each partition and set the runtime target a WebSphere Liberty installation\n  *\tImport the partition from the filesystem into the project\n  *\tEnsure all partitions module folders containing Java source files are correctly configured as source folders within the Eclipse tools, rooted where the package directories are (this includes the monolith module folders as well as the application utility code folder generated by Cardinal. See previous section)\n  *\tBuild the project and observe any compilation errors\n\nIn this lab, you will make the minimal set of changes for the web and partition0 partitions that are required to compile and run the front-end microservice (web) and the back-end microservice (back-end) in Liberty Server in containers.\n\nIt is beyond the scope of this lab to take each microservice through the iterative development process in an IDE. But you will get the point, if you spend a little time reviewing the updates that are done via the provided scripts. Itâ€™s not that extensive for this simple application. \n\n**7.4.4.1.** Move the original non-Java resources from the monolith to the two new partitions\n\nAs described above, the first step is to Copy **all** non-Java files to **every** partition, following the same directory structure which will partially already exist in each of the generated partitions.\n\nFor this lab, a shell script has been provided for you, which will copy all the resources to the partitions. \n\nThis is the first step to refactoring the partitions. Further refactoring of these artifacts is unique to the microservice functionality in each partition.  \n\nThe script performs the following tasks: \n  *\tCopies the various pom.xml files to both partitions\n  *\tCopies all the webapp artifacts (html, jsp, xml) files to both partitions\n  *\tCopies the application EAR resources to both partitions\n  *\tCopies the Liberty server configuration file to both partitions\n  *\tCopies the database configuration files to the back-end partition\n\n**_1.**\tReview the moveResourcesToPartitions.sh shell script.   \n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\ngedit moveResourcesToPartitions.sh\n```\n  \nThe script:\n  * defines a bunch of variables referencing various directories for copying files\n  * uses sudo to change directory permissions to allow write access to the partitions that mono2 micro generated\n\n![](images/80-move-script.png)\n\n  * copies non-java resources from the monolith application to the (front-end) web partition\n    \n![](images/81-move-script-2.png)\n    \n  * script copies non-java resources from the monolith application to the (back-end) partition0 partition\n \n![](images/82-move-script-3.png)\n\n**_2.**\tClose the editor \n\nTo speed up copying files, run the moveResourcesToPartitions.sh script to do it for you. \n\n**_3.**\tRun the script to copy the non-java resources to the partitions\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\n./moveResourcesToPartitions.sh\n```\n\nWhen prompted for a password, enter: **passw0rd**\n\n**_4.**\t Use a graphical File Explorer   or Terminal window to see the non-Java files now in each of the partitions, and in the same directory structure as the original monolith. \n\n**a.**\tNavigate to the following directories to explore the newly added non-Java resources. Refer to the shell script to see what exactly was copied. \n  *\t/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web\n  *\t/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0\n\n**7.4.4.2.**  Refactor the original non-Java resources as required for the front-end and back-end partitions\n\nAt this point, every partition contains all the Java and non-Java files necessary for the application. \n\nStarting with that as a base, the next step is to pare down and incrementally reduce the content of all these files, ending up with just the needed content in each partition to build and run the microservice. \n\nIn this lab, you will focus only on the refactoring that is required for the partitions to compile and run in Docker containers. An iterative for further paring down the content is beyond the scope of this lab. \n\nTo simplify the refactoring activities for this lab, a shell script has been provided that performs the refactoring required such that each partition (microservice) will compile and run on their own Liberty Server in separate Docker containers.  \n\nThe script performs the following tasks for the web partition:\n  *\tCreate a new pom.xml file to build the Cardinal Utility classes generated by Mono2Micro\n  *\tUpdates the top level pom.xml file to include the Cardinal Utilities module to be built with the app\n  *\tUpdates the DefaultWebApplication pom.xml file to remove Java persistence dependency\n  *\tUpdate the DefaultApplication-ear pom.xml file to remove the database config \n  *\tUpdate the DefaultApplication-ear pom.xml file to add Dependency for Cardinal Utility classes \n  *\tUpdate Liberty server.xml file to remove database / datasource configuration\n  *\tAdd a dockerfile to build the Microservice and Docker image running on Liberty\n\nThe script performs the following tasks for the partition0 partition:\n  *\tCreate a new pom.xml file to build the Cardinal Utility classes generated by Mono2Micro\n  *\tUpdates the top level pom.xml file to include the Cardinal Utilities module to be built\n  *\tUpdates the DefaultWebApplication pom.xml file to remove Java persistence dependency\n  *\tUpdate the DefaultApplication-ear pom.xml file to remove the database config \n  *\tUpdate the DefaultApplication-ear pom.xml file to add Dependency for Cardinal Utility classes \n  *\tUpdate and move the JAXRSConfiguration.java file to DefaultWebApplication class path. \n    *\tUpdate the package in the Java file to match source location in the module.  \n    *\tThis Java file is generated by Mono2Micro\n  *\tUpdate the IncrementActionService.java file \n    *\tThis Java file is generated by Mono2Micro.  \n    *\tThis works around a known issue with conflicting import statements in the Java file \n  *\tAdd a dockerfile to build the Microservice and Docker image running on Liberty\n\n**_1.**\tRun the refactorPartitions.sh shell script to perform the partition refactoring\n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\n./refactorPartitions.sh\n```\n\nWhen prompted for a password, enter: **passw0rd**\n\n![](images/83-refactor-script.png)\n\n![](images/84-refactor-script-2.png)\n \nIn a production application, refactoring the resources within each Microservice could take significant time. \n\nThe aim is to pare down and incrementally reduce the content of all these files (based on knowledge of what functionality each microservice entails) and through an iterative **compile-run-debug** process, ending up with just the needed content for each microservice.\n\nIf you are interested in the details of the refactored files that were pared down for this lab, refer to APPENDIX B in this lab guide. APPENDIX B:  Examine the Refactored resources after code generation provides a detailed look at these refactored files. \n\n**7.4.4.3.**  Deploy Partitions as Containerized Microservices\n\nTo portably run the builds of all the partitions, and at the same time prepare them for containerization, this lab uses Docker based builds right from the start.\n\nMulti-stage dockerfiles are used for each partition: \n  *\tStage 1: Performs the Maven build and packaging of the deployable artifacts (WAR, EAR, JAR)\n  *\tStage 2: Creates the Docker image from OpenLiberty, and adds the application, server configuration, and other configurations required for the partitions (Derby DB config) \n\nThe dockerfile is slightly different for each partition since each partition will require unique configurations for its Microservice.  \n\n**_1.**\tNavigate to the Dockerfile in the web partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/Dockerfile\n```\n  \n![](images/85-dockerfile-web.png)\n\nBuild Image stage: \n  *\tPerforms the Maven Build and package of the application based on the pom.xml files in the project. \n\nProduction Image stage: \n  *\tPulls the Universal base Image (UBI) of Open-Liberty Docker image from Dockerhub. The Universal Base Image is the supported images when deploying to RedHat Openshift. \n  *\tCopy the EAR to the Liberty apps directory, where Liberty will automatically start when the container is started. \n  *\tCopy the Liberty server configuration file to Liberty config directory, which is used to configure the Liberty runtime.\n  *\tAs root user, I install curl as a tool for helping to debug connectivity between Docker containers. This is not required. \n  *\tAs root user, update the permissions on the shared resources folder in Liberty\n\nENV Variables required by Mono2Micro\n\nAdditionally, each partition is passed environment variables specifying the end point URLs for JAX-RS web services in other partitions. \n  *\tThe Cardinal generated code uses these environment variables in the proxy code to call the JAX-RS services\n  *\tIt is important to note that for JAX-RS, URLs cannot contain underscores.   \n\nExample ENV Variable for the web partition: \n  \n**ENV APPLICATION_PARTITION0_REST_URL=http://defaultapp-partition0:9080/rest/**\n\n  *\tWhen running in Docker, a docker network must be set up so that all partitions can communicate with each other. Yu did this in the lab. \n  *\tAll partitions in this lab use port 9080 internally within the Docker environment, but expose themselves on separate ports externally to the host machine\n  *\tUsing this scheme as a base, a Kubernetes deployment can be set up on a cluster where each container acts a Kubernetes service\n\nWhen running in Docker, the hostname must match the **Name** of the container as known in the Docker Network. \n  *\tUse command: **docker network list** to see the list of docker networks\n  *\tUse command: **docker network inspect &ltNETWORKNAME&gt** to see the container names in the Docker network. \n  \nWhere **&ltNETWORKNAME&gt** is the name of the Docker network to inspect\n\n![](images/86-docker-networkname.png)\n\n**_2.**\tNavigate to the Dockerfile in the partition0 partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0/Dockerfile\n```\n\n![](images/87-dockerfile-partition0.png)\n\nBuild Image stage: \n  *\tPerforms the Maven Build and package of the application based on the pom.xml files in the project. \n\nProduction Image stage: \n\nIn addition to the steps that were performed in the web partition, these additional steps are required for the partition0 Microservice deployment. \n  *\tCopies the Derby DB zip file to the shared resources folder for Liberty. The Maven build has a step to unzip the Database contents.\n  *\tCopies the Derby database JDBC library to Libertyâ€™s shared resources folder\n\nNote: The partition0 partition does not require any Mono2Micro ENV variables to be set since this partition doe not make any REST API calls to other partitions. \n\n**7.5.**  Build (Compile) the transformed Microservices using Maven\n\nIn the previous sections of the lab, you used the Mono2Micro tools to transform the original monolith application into two microservices. \n\nThen, using the convenience scripts we provided, you started to refactor the microservices by moving the non-java resources and Liberty configuration into the microservices projects. \n\nYou further refactored the microservices by paring down the non-java configuration files, Liberty configuration, and Maven build artifacts to include only the configuration required to build and run each of the microservices in their own Liberty runtime in containers.  \n\nAt this point, it would be a good idea to do a quick compilation of the microservices to see if there are any compilation or build errors. Then, iterate on the refactoring of each microservice, as needed. \n\nIdeally, developers would do try doing a quick compilation of the generated code by using an IDE tailored to support Java EE and the application server. \n\nUsing an IDE for development is beyond the scope of this lab. Instead, you will simply use Maven to test the compilations of the microservices and observe any compilation errors. \n\n**_1.**\tCompile the monolith-web microservice via command line\n  \n**a.**\tChange to the monolith-web directory, which contains the top-level pom.xml for building the monolith-web microservice \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web\n```\n  \n**b.**\tRun the Maven Build to compile and package the microservice\n\n```\nmvn clean install\n```\n    \nIf all goes well, the microservice project will compile successfully, as illustrated below:\n\n![](images/88-mvn-install-web.png)\n \n**_2.**\tCompile the monolith-partition0 microservice via command line\n\n**a.**\tChange to the monolith-partition0 directory, which contains the top-level pom.xml for building the monolith-web microservice \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0\n```\n\n**b.**\tRun the Maven Build to compile and package the microservice\n\n```\nmvn clean install\n```\n    \nIf all goes well, the microservice project will compile successfully, as illustrated below:\n\n![](images/89-mvn-install-partition0.png)\n  \n**The last section of the lab below is OPTIONAL!**\n\nAt this point in the lab. you are back to where this lab started. Recall in Part 1 of the lab, you built and ran the DefaultApplication as microservices in containers using Docker. Those microservices were also transformed using Mono2Micro, using resources we provided in the Git Repo. \n\nNow itâ€™s your turn! \n\nTo bring the lab full circle, you may continue to the last section of this lab to build and run YOUR transformed and refactored Microservices application.  \n\n**7.6.** OPTIONAL: Build and run the Transformed Java Microservices Using Docker\n\n**_1.**\tStop and remove the currently running docker containers that you deployed d Part 1 of the lab\n\n```\ndocker stop defaultapp-web\n\ndocker rm defaultapp-web\n\ndocker stop defaultapp-partition0\n\ndocker rm defaultapp-partition0\n\ndocker ps | grep defaultapp\n\ndocker ps -a | grep defaultapp\n```\n  \nNOTE: The docker containers should no longer exist. \n\n**_2.**\tRemove the DefaultApplication Docker images that you created in part 1 of the lab\n\n```\ndocker rmi defaultapp-web\n\ndocker rmi defaultapp-partition0\n\ndocker images | grep defaultapp\n```\n\nNOTE: The docker images should no longer exist. \n\n**_3.**\tBuild and start the defaultapplication-web (front-end) container\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-web\n\ndocker build -t defaultapp-web  . | tee web.out\n\ndocker run --name=defaultapp-web --hostname=defaultapp-web --network=defaultappNetwork -d -p 9095:9080 defaultapp-web:latest\n\ndocker ps | grep defaultapp\n```\n\n**_4.**\tBuild the defaultapplication-partition0 (back-end) container\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0\n\ndocker build -t defaultapp-partition0 . | tee partition0.out\n\ndocker run --name=defaultapp-partition0 --hostname=defaultapp-partition0 --network=defaultappNetwork -d -p 9096:9080 defaultapp-partition0:latest\n\ndocker ps | grep defaultapp\n```\n  \n![](images/90-docker-ps.png)\n  \nOnce all the containers have started successfully, the DefaultApplication can be opened at http://localhost:9095/\n \nThat completes the end-to-end lab: Using Mono2Micro to transform a Java monolith application to Microservices. \n\n### Conclusion\n\nIn this lab, you gained significant hands on experience using Mono2Micro in a full end-to-end flow. \n\nYou started by building and running the final transformed microservices based application in Docker containers running on Liberty server. \n\nThen, you started from the beginning with a Java EE monolith application, using the AI-driven Mono2Micro tools to analyze it and recommend the different ways it can be partitioned for potential microservices. \n\nUsing Mono2Microâ€™s UI, you further customized the partitioning to suit our specific requirements. \n\nYou then used the unique code generation tool to generate a bulk of the foundation microservices code, while allowing the monolith Java classes to stay completely as-is without any rewriting. \n\nAnd then with further manual refactoring of the non-Java aspects of the monolith, a set of microservices are deployed in containers that provides the exact same functionality as the monolith application.\n\n\n### **Appendix A:  Examine the Java Code generated by Mono2Micro**\n\n**A.1.**   Explore Cardinal some notable Java resources generated in the web partition\n\nFully exploring all the resources in detail is beyond the scope of this lab. You will explore a few of the key resources in the partitions. Feel free to explore in more detail if you desire. \n\n**1.**\tUsing the File Explorer, navigate to the monolith-web directory **Home > m2m-ws-sample > defaultapplication > monolith-web**.\n\n**2.**\tFirst, letâ€™s look at the UTILITY classes in the application subdirectory of the **monolith-web** folder. \n\nNotice the folder named **application**.  This folder contains the Utility classes that handles the plumbing for the microservices. It has classes for handling serialization, exceptions, logging, etc. These classes are generated for ALL partitions. \n\n![](images/a1-1-monolith-web.png)\n\n![](images/a1-2-util.png)\n \nTip: The default name for the Utility classes is **application**. However, this is configurable in the app_config.txt file that is generated by the AIPL tool.  \n \n![](images/a1-3-app-config.png)\n  \nThe **app_config.txt** file is located here: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\n**3.**\tExplore the DefaultWebAplication subdirectory in the monolith-web folder. \n\n  *\tOriginal classes: The original HitCount.java and SnoopServlet classes are copied directly from the original monolith application\n \n![](images/a1-4-java.png)\n   \n  *\tProxy class: Cardinal generated a proxy class for IncrementAction. The proxy invokes the IncrementActionService URL in partition0.\n \n![](images/a1-5-defaultapp.png)\n   \n  * Dummy classes: Cardinal generated Dummy classes for classes that are present in the original monolith but are moved to a different partition. The Dummy classes simply throw custom exceptions in the event these classes are unexpectedlyinvoked.   \n\n  Dummy classes for Increment.java and IncrementSSB.java were generated. \n \n![](images/a1-6-defaultapp-2.png)\n\n**A.2.**   Explore Cardinal some notable Java resources generated in the partition0 partition\n\nFully exploring all the resources in detail is beyond the scope of this lab. You will explore a few of the key resources in the partitions. Feel free to explore in more detail if you desire. \n\n**1.**\tUsing the File Explorer, navigate to the **monolith-partition0** directory: **Home > m2m-ws-sample > defaultapplication > monolith-partition0**.\n\nThe UTILITY classes in the application subdirectory of the monolith-partition0 partition are the same as those generated in the web partition. These utility classes are required from each microservice.   \n\nNotice the folder named **application**.  This folder contains the Utility classes that handles the plumbing for the microservices. It has classes for handling serialization, exceptions, logging, etc. These classes are generated for ALL partitions.  \n \n![](images/a2-1-monolith-partition0.png)\n\n![](images/a2-2-util.png)\n\nCardinal generated a Java resource named **JAXRSConfiguration.java**. This file is in the **config** sub-directory under the application subdirectory of the monolith-partition0 partition.  \n    \n![](images/a2-3-config.png)\n \nAs part of the utility code that Cardinal generates, a JAXRSConfiguration class is generated per partition. \n\nFor now, it is important to know this class sets up the JAX-RS config where all service classes are registered and is meant to be copied over and placed in one Java EE module of your preference within each partition. You will work with this file later in the lab as you do final preparation of the microservices for deployment to Liberty Servers in Containers. \n \n![](images/a2-4-jaxrs-config.png)\n \n**user_defined.txt** - A related file that you might notice is the presence of a user_defined.txt file in /home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal which the Cardinal tool reads on start-up, if one exists. \n\nThis is a way to provide a list of one or more monolith classes that are to be treated as **external facing**, where classes outside its partition might call into it. These external facing classes are also called **service classes** in Mono2Micro nomenclature. \n\nRecall that the deep partition analysis report Cardinal-Report.html generated by AIPL lists all external facing classes per partition that the AI analysis deemed necessaryâ€¦ but there could always be cases where some classes were not called out as such (typically due to insufficient use cases being run that allows Mono2Micro to observe this external facing behavior). \n\nThe user_defined.txt file provides the ability to define additional Java classes as external facing **service classes**, if needed. \n\n**2.**\tExplore the DefaultWebApplication subdirectory in the monolith-partition0 folder. \n  * Original classes: The original classes are copied directly from the original monolith application: \n    *\tIncrement.java\n    *\tIncrementAction.java\n    *\tIncrementSSB.java\n\n![](images/a2-5-defaultapp.png)\n \n  * Service class: Cardinal generated a Service class names IncrementActionService. The service class is the REST Service interface to the IncrementAction service.\n \n![](images/a2-6-defaultapp-2.png)\n\n![](images/a2-7-incrementaction-class.png)\n   \n  *\tDummy classes: Cardinal generated Dummy classes for classes that are present in the original monolith but are moved to a different partition. The Dummy classes simply throw custom exceptions in the event these classes are unexpectedlyinvoked.   \n\n  Dummy classes for HitCount.java and SnoopServlet.java were generated. \n \n![](images/a2-8-java.png)\n\n### **Appendix B: Examine the Refactored resources after code generation** \n\nIn this appendix, you will explore a variety of refactored resources that are representative of the types of refactoring required from many Java application. We will not explore every refactored file. However. You may explore deeper, if desired.  \n\n**B.1.** Cardinal Utility Code Module\n\nFirst, to build the generated Cardinal utility code in each partition, this lab we kept the generated application/ folder, but you could have chosen to rename it to something like to cardinal-utils/ to better identify the modules purpose. \n\nThen, we put together a **pom.xml** fashioned after the monolithâ€™s web moduleâ€™s pom files, to build it as a utility .jar (with the aim of then including it as an additional module in the partition .ear file):\n\n**1.**\tNavigate to the new **Cardinal Utilities** pom.xml file to view its contents in the web partition. This file was created in ALL partitions. \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/application/pom.xml\n```\n\nThis pom.xml file will build a Cardinal Utilities jar file and be included in the partition. The top level pom.xml file was also refactored to include this module for Maven to build\n  \n![](images/b-1-pom.png)\n   \n**B.2.** Partitions Build Config\n\nNext, for each partition, the root pom.xml that was copied from the monolith was modified to include the new cardinal-utils module.\n\n**1.**\tNavigate to the top-level pom.xml file in the web partition to view this update. This update was made to all the top-level pom.xml in each partition.  \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/pom.xml\n```\n\nThe included module to build the Cardinal Utilities must match the **artifactID** in the Cardinal Utils pom.xml that you explored above. \n\nIn this case, it is **application**. It might have been better to rename the module to something like cardinal-utils. But that could be done in another round of refactoring.  \n  \n![](images/b-2-pom.png)\n\n**B.3.** JAX-RS Configuration\n\nNext look at how to facilitate the JAX-RS code generated by Mono2Micro as these partitions are run on the app server. \n\nFirst, as part of the utility code that Cardinal generates, a JAXRSConfiguration class is generated for each partition that has one or more service classes. A service class is class generated by Cardinal that handle incoming REST API calls from outside of the partition.  \n\nThis JAXRSConfiguration class sets up the JAX-RS config where all service classes are registered and is meant to be copied over and placed in one Java EE module of your preference within each partition so that it is in the serverâ€™s class path. \n\nFor this DefaultApplication example, partition0 partition is the only partition that has a service class. I chose to place the java file in the web module in partitton0, in the same source location as the IncrementActionService class. \n\n**1.**\tNavigate to the JAXRSConfiguration java file in the partition0 partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0/DefaultWebApplication/src/main/java/com/ibm/defaultapplication/JAXRSConfiguration.java\n```\n\nYou must specify the package for the class based on where you place the file in the project. \n\nNotice that this class registered the IncrementActionService class that Cardinal generated. \n  \n![](images/b-3-jaxrs-config.png)\n    \n**B.4.** Application Server Config Per Partition\n\nFor this DefaultApplication example, the Liberty server config (server.xml) that originally came in the monolith was copied to each partitions ear module. \n  *\tThe contents of the monolithâ€™s server.xml were **as-is** for parttion0 partition.\n  *\tThe Datasource configuration was removed from the server.xml in the web partition\n\t\nUsually the Liberty server.xml can be further customized and reduced to pull in only applicable server features to each partition.  \n\nIf the original monolith was running on a traditional WebSphere server, and you wish to run the partitions on Liberty, a server.xml can either be handcrafted, or created with the assistance of IBMâ€™s other migration and modernization tools. \n\nOf course, this would only be possible if the monolith uses functionality that WebSphere Liberty supports.  \n\nAdditionally, each partitionâ€™s server.xml also needs to add JAX-RS related features if they already donâ€™t exist, in order to facilitate the generated codeâ€™s JAX-RS webservice service and client code: \n\n<feature>jaxrs-2.0</feature>\n<feature>mpConfig-1.2</feature>\n<feature>mpOpenAPI-1.0</feature>\n\n**1.**\tNavigate to the server.xml file in the web partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/DefaultApplication-ear/src/main/liberty/config/server.xml\n```\n\n![](images/b-4-server-xml.png)\n\n### Appendix C: How can I do this lab using my own environment? \n\nIt is possible to do this lab using your own environment instead of the Skytap environment provided. \n\nNOTE: The prerequisite software listed in the prerequisites section of the lab MUST be installed on your local environment. \n\nThere were only 3 changes that we had to do, in addition to the obviously issuing commands using your own path instead of /home/ibmadmin:\n \n**Section # 7.3 - Run test cases using the instrumented monolith for Runtime data analysis**\n  *\tEdit the scripts m2m-ws-sample/defaultapplication/scripts/startServer.sh and m2m-ws-sample/defaultapplication/scripts/serverStatus.sh to adjust the path to your own environment\n  * OR run the commands manually\n\n```\n$LAB_HOME/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/bin/server start DefaultApplicationServer\n\n$LAB_HOME/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/bin/server status DefaultApplicationServer\n```\n\n**Section # 7.4.4.1 - Move the original non-Java resources from the monolith to the two new partitions**\n  *\tEdit moveResourcesToPartitions.sh to adjust the path to your own environment, here: WORKDIR=\"$LAB_HOME/m2m-ws-sample\")\n \n**Section # 7.4.4.2 - Refactor the original non-Java resources as required for the front-end and back-end partitions**\n  *\tEdit $LAB_HOME/m2m-ws-sample/defaultapplication/scripts/refactorPartitions.sh to adjust the path to your own environment, here: WORKDIR=\"$LAB_HOME/m2m-ws-sample\"\n\n### **Appendix D: How to use Copy / Paste between local desktop and Skytap VMs**\n\nIn SkyTap, you will find that any text copied to the clipboard on your local workstation is not available to be pasted into the VM on SkyTap. You have to use the copy / Paste capabilities between the lab document on your local workstation to the VM is a good approach to more efficiently work through a lab, while reducing the typing errors that often occur when manually entering data. \n\n**1.** First copy the text you intend to paste, from the lab document, to the clipboard on your local workstation, as you always have (CTRL-C)\n\n**2.** Return to the SkyTap environment and click on the Clipboard at the top of the SkyTap session window. \n \n![](images/d-1-clipboard.png)\n  \n**3.** Use **CTRL-V** to paste the content into the Copy/paste VM clipboard. Or use the paste menu item that is available in the dialog, when you right mouse click in the clipboard text area. \n \n![](images/d-2-clipboard-2.png)\n  \n**4.** Once the text is pasted, just navigate away to the VM window where you want to paste the content. Then, use CTRL-C, or right mouse click & us the paste menu item to paste the content. \n \n![](images/d-3-paste.png)\n  \nThe text is pasted into the VM.\n\n![](images/d-4-paste-done.png)\n \nNote: The very first time you do this, if the text does not paste, you may have to paste the contents into the Skytap clipboard twice. This is a known Skytap issue. It only happens on the 1st attempt to copy / paste into Skytap. \n","type":"Mdx","contentDigest":"120a9469d8f3d0acc79d99d68e82a0ba","counter":485,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Getting Started with IBM Mono2Micro","description":null},"exports":{},"rawBody":"---\ntitle: Getting Started with IBM Mono2Micro\ndescription: \n---\nOne of the best ways to modernize business applications is to refactor them into microservices, allowing each microservice to be then independently enhanced and scaled, providing agility and improved speed of delivery. \n\nIBM Mono2Micro is an AI-based semi-automated toolset that uses novel machine learning algorithms and a first-of-its-kind code generation technology to assist you in that refactoring journey to full or partial microservices, all without rewriting the Java application and the business logic within. \n\nIt analyzes the monolith application in both a static and dynamic fashion, and then provides recommendations for how the monolith can be partitioned into groups of classes that can become potential microservices. \nBased on the partitioning, Mono2Micro also generates the microservices foundation code and APIs which alongside the existing monolith Java classes can be used to implement and deploy running microservices.\n\n![](images/1-m2m.png)\n\n### **1. Business Scenario**\n\nYour company has a traditional WebSphere Application Server application called **DefaultApplication**, a monolith web application provides the following servlet functions:\n\n![](images/7-default-app.png)\n\n**Snoop servlet**\n\nUse the Snoop servlet to retrieve information about a servlet request. This servlet returns the following information:\n \n  * Servlet initialization parameters\n  * Servlet context initialization parameters\n  * URL invocation request parameters\n  * Preferred client locale\n  * Context path\n  * User principal\n  * Request headers and their values\n  * Request parameter names and their values\n  * HTTPS protocol information\n  * Servlet request attributes and their values\n  * HTTP session information\n  * Session attributes and their values\n\nThe Snoop servlet includes security configuration so that when WebSphere Security is enabled, clients must supply a user ID and password to initiate the servlet.\n\n**HitCount application**\n\nUse the HitCount demonstration application to demonstrate how to increment a counter using a variety of methods, including:\n  * A servlet instance variable\n  * An HTTP session\n  * An enterprise bean\n\nYou can instruct the servlet to execute any of these methods within a transaction that you can commit or roll back. If the transaction is committed, the counter is incremented. If the transaction is rolled back, the counter is not incremented.\n\nThe enterprise bean method uses a container-managed persistence enterprise bean that persists the counter value to an Apache Derby database. This enterprise bean is configured to use the DefaultApp Datasource, which is set to the DefaultDB database.\n\nWhen using the enterprise bean method, you can instruct the servlet to look up the enterprise bean, either in the WebSphere global namespace, or in the namespace local to the application.\n\n\nAs a tech leader, you are leading the effort to use IBM Mono2Micro to transform the monolith application to Microservices.\n\n### **2. Getting Started with Mono2Micro**\n\nBelow is a high-level flow diagram of getting started with Mono2Micro in collecting data on an existing monolith application, and then running the AI analyzer tool to generate two kinds of recommendations as how to partition the application into recommended microservices.\n\n![](images/2-m2m-flow.png)\n\n  *\tThe data is collected from static code analysis, capturing data (Class) dependencies, depicted in [1].\n  *\tData is dynamically collected through runtime trace logs as the instrumented monolith application is run through various use case scenarios to exercise as much of the codebase as possible, depicted in [2] & [3].  \n\nBased on all three kinds of data, Mono2Micro generates a Natural Seams Partitioning recommendation that aims to partition and group the monolith classes such that there are minimal class containment dependencies and entanglements (i.e. classes calling methods outside their partitions) between the partitions. \n\nThe **Data Dependency Analysis** in [1] refers to this kind of dependency analysis between the Java classes. In effect, this breaks up the monolith along its natural seams with the least amount of disruption.\n\nBased on [2] and [3] alone, and not taking class containment dependencies and method call entanglements into account, Mono2Micro also generates a Business Logic Partitioning that might present more entanglements and dependencies between partitions, but ultimately provides a more useful partitioning of the monolith divided along functional and business logic capabilities.\n\n#### **2.1. How does Mono2Micro work?**\n\nIn this lab, you will use a simple JEE monolith application named **DefaultApplication**, and step through the entire Mono2Micro toolset, end to end, starting with the monolith and ending with a deployed and containerized microservices version of the same application. \n\nMono2Micro consists of five components, each of them serves a specific purpose. The component and their uses are listed in the following:\n\n**Bluejay** - instruments the Java source code of monoliths. The instrumentation captures entry and exit of every Java method in the application. \n\n**Flicker** - A Java program that is used while running test cases that gathers runtime analysis data. Flick is used to align the start and end times of a use case with the timestamps generated from the instrumented code. This allows for Mono2Micro to track the code being executed in the monolith to specific use cases.  \n\n**AIPL** - The AI engine of Mono2Micro which uses machine learning and deep learning techniques on the user supplied runtime traces and metadata obtained from Bluejay and Flicker to generate microservice recommendations. AIPL also produces a detailed report for the recommended microservices.\n\n**Mono2Micro UI** - The results obtained from AIPL are stored in userâ€™s local storage. The results can be uploaded to Mono2Micro UI to display them in a graphical visualizer. The UI also allows user to modify the AIPL generated microservice recommendations.\n\n**Cardinal** - The program with deep knowledge of the semantics of the Java programming language. Cardinal uses the recommendations from AIPL. \n\nCardinal performs these important capabilities:\n  *\tProvides detailed invocation analyses of the recommended microservices\n  *\tGenerates a significant portion of the code needed to realize the recommended microservices in containers\n\n#### **2.2. Mono2Micro usage flow**\n\nThe illustration below shows how the Mono2Micro components fit into the end-to-end process. \n\n![](images/3-m2m-flow.png)\n\nAt this point, do not get bogged down with the details in the diagram. You will explore these details as you progress through the lab. \n  *\tUse Bluejay to instrument the monolith application\n  *\tUse Flicker and run test cases to capture runtime execution Trace data in the server logs, based on the instrumented code, updated by Bluejay.  \n  *\tUse AIPL to analyze the data and produce recommended microservices based on Natural Seams and/or Business logic. \n  *\tUse Mono2Micro UI to visualize the microservices recommendations, and tweak the recommendations as needed to meet your objectives.  \n  *\tUse Cardinal to generate the plumbing and service code needed to realize the recommended microservices. \n\n### **3. Objective**\n\nThe objectives of this lab are to help you:\n  * Learn how to perform the end-to-end process of using Mono2Micro to analyze a Java EE monolith and to transform it to Microservices\n  *\tLearn how to build and run the transformed microservices in containers using Docker and OpenLiberty\n\n### **4. Prerequisites**\n\nThe following prerequisites must be completed prior to beginning this lab:\n  *\t3 GB free storage for the Mono2Micro Docker images and containerized microservices\n  *\tDocker 17.06 CE or higher, which supports multi-stage builds\n  *\tGit CLI (needed to clone the GitHub repo)\n  *\tJava 1.8  \n  *\tMaven 3.6.3\n  *\tInternet connectivity with access to dockerhub and maven-central\n  *\tUnderstanding of command line for your environment \n\n### **5.\tWhat is Already Completed**\n\nOne (1) Linux CentOS version 7 VM has been provided for this lab. \n\n![](images/4-vm.png)\n\nUse the link below to reserve your Lab environment:\n\nhttps://dte2.us1a.cirrus.ibm.com/my/reservations/create/5fd399855bdac2001e0d42f8\n\nThe Workstation VM has the following software installed (you can use your own workstation with the same configurations):\n  *\tDocker 19.03.13\n  *\tGit 2.24.1\n  *\tMaven 3.6.3\n  *\tJava OpenJDK 1.8.0\n\nThe login credentials for the Workstation VM are:\n\nUser ID: **ibmadmin**\n\nPassword: **passw0rd**          \n\n**Note: You can also use your own workstation as the lab environment with the same configuration listed above. You only need to make three changes highlighted in Appendix C.**\n \n### **6.\tLab Tasks**\nDuring this lab, you complete the following tasks:\n  *\tLogin to the Workstation VM and Get Started\n  * Build and run the Transformed Java Microservices Using Docker\n  * Use Mono2Micro to analyze the Java EE monolith application and recommend microservices partitions\n  * Generating Initial Microservices Foundation Code\n\n### **7.\tExecute Lab Tasks**\n\n#### **7.1. Log in to the Workstation VM and get started** \n\n**_1.**  If the VM is not already started, start it by clicking the Play button.\n \n![](images/5-start-vm.png)\n\n**_2.**\tAfter the VM is started, click the Workstation VM icon to access it. \n \n![](images/6-select-vm.png)\n\n**_3.**\tEnter the password as **passw0rd** and log in.\n\nThe Workstation Desktop is displayed. You execute all the lab tasks on this VM.\n\n### **Part 1**\n#### **7.2. Build and run the Transformed Java Microservices Using Docker**\n\nBefore you get started using Mono2Micro to transform a monolith application to Microservices, letâ€™s fast forward to the end results and see the transformed microservices in action. \n\nThe resources we provide for this lab includes the **Completed and Transformed** Microservices as a result of using Mono2Mico. \n\nThe goal here is to just let you see the transformed Microservices in a working state before you work through the transformation process yourself. \n\n**Objectives**\n  *\tSee the transformed monolith application running as independent microservices on OpenLiberty in separate Docker containers, before you use Mono2Micro to transform the monolith in this lab.\n  *\tLearn how to build and run the transformed microservices with Docker and OpenLiberty\n\nIn this part of the lab, you build and deploy the microservices that have already been transformed using Mono2Micro. \n\nYou leverage new and updated build components that have been created in Mono2Micro refactoring phase in order to build and run the microservices as independent OpenLiberty server runtimes in Docker containers. \n\nThe basic steps in this part of the lab include: \n  *\tClone the GitHub repository that contains the resources required for the lab\n  *\tUse Docker to build the two transformed microservices for the application \n  *\tSetup a local Docker Network for the local docker containers to communicate\n  * Start the docker containers and run the microservices based application\n  *\tView the microservices logs to see the communication and data flowing between the services as you test the application from a web browser\n\nThe GitHub repository contains all the source code and files needed to perform all the steps for using Mono2micro to transform the monolith application used in this lab to microservices, including:\n  * The DefaultApplication Source Code\n  *\tThe newly constructed dockerfiles to build and run the microservices in containers\n  *\tThe updated POM files that have been reduced to contain only the resources needed for the individual microservice\n \nStructure of the m2m-ws-sample GitHub repository is as follows (details in the README within the GitHub repo):\n  * Monolith source code: ./defaultapplication/monolith\n  * Monolith application data: ./defaultapplication/application-data/\n  * Mono2Micro analysis (initial recommendations): ./defaultapplication/mono2micro-analysis\n  * Mono2Micro analysis (further customized): ./defaultapplication/mono2micro-analysis-custom\n  * Deployable Microservices: ./defaultapplication/microservices\n\n**_1.**\tClone the GitHub repository by openning a Terminal window and running the following commands:\n\n```\ncd /home/ibmadmin\n\ngit clone https://github.com/kpostreich/m2m-ws-sample\n\n```\n\n![](images/8-git-clone.png)\n\n**_2.**\tChange to the directory that contains the artifacts needed to build and run the generated microservices in local Docker containers. The artifacts needed to build and run the two microservices, generated by Mono2Micro, are in the /home/ibmadmn/m2m-ws-sample/defaultapplication/microservices/ folder.\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/\n```\n\n**_3.** Build the resulting microservices in Docker containers\n\nLetâ€™s do a basic overview of the two microservices that form the DefaultApplication used in this lab.\n\nFirst, notice that there are two services. Mono2Micro places these services into logical partitions. The **web** partition is the UI front-end microservice. It includes the HTML, JSPs, and Servlets, all needed to run within the same Web Container, according to JEE specifications. The **partition0** partition is the backend service for the IncrementAction service. It contains an EJB and JPA component that is responsible for persisting the data to the embedded Derby database used by the microservice. \n \n![](images/9-web-partition0.png)\n\nWeb partition (front-end microservice) invokes partition0 (back-end), when the HitCount Service via EJB is executed by the user. \n\nWhat happens is the HitCount Servlet in the **Web partition** invokes a Rest Service interface in **partition0** through a local HitCount proxy, both generated by Mono2Micro as plumbing code for invoking the RESTful Microservices. \n\n![](images/10-web-partition0-details.png)\n\n**a.**\tCreate a Docker Network for the two containers to communicate.   \n    \nYou will use Docker to build and run the microservices based application. For the Docker containers to communicate, a local Docker network is required. \n\nTip: Later, when you launch the Docker containers, you will specify the network for the containers to join, as command line options. \n\n```\ndocker network create defaultappNetwork\n\ndocker network list\n```\n\n![](images/11-docker-network-list.png)\n\nNote: When using a Kubernetes based platform like RedHat OpenShift, the service to service communication is automatically handled by the underlying Kubernetes platform. \n \n**b.**\tBuild the defaultapplication-web (front-end) container.\n    \nThis container is the web front end service. It contains the html, jsp, and servlets. \n    \nThe defaultapp-web folder contains the Dockerfile used to build the front-end microservice. \n  \n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-web\n\ndocker build -t defaultapp-web  . | tee web.out\n```\n\nThe dockerfile performs these basic tasks:\n  *\tUses the projects pom.xml file to do a Maven build, which produces the deployable EAR. \n  *\tCopies the EAR file and OpenLiberty Server configuration file to the appropriate location in the Docker container for the microservice to start once the container is started.\n\n![](images/12-docker-build.png)\n\n**c.**\tStart the partition-web (front-end) docker container.\n\nNotice the command line options that are required for the microservice to run properly. \n  *\tThe partition-web container needs to expose port 9095 for the application to be invoked from a web browser. The OpenLiberty sever is configured to use HTTP port 9080 internally. \n  *\tThe container must be included in the defaultappNetwork that you defined earlier. The back-end microservice will also join this network allowing the services to communicate with one another. \n\n```\ndocker run --name=defaultapp-web --hostname=defaultapp-web --network=defaultappNetwork -d -p 9095:9080 defaultapp-web:latest\n\ndocker ps\n```\n  \n![](images/13-docker-ps.png)\n\nNote: The application is exposed on port 9095 and running on port 9080 in the container.\n \n**d.**\tBuild the defaultapplication-partition0 (back-end) container.\n\nThis container is the back-end service. It contains EJB and JPA components that persists data to the Derby database, when the user executes the HitCount service with the EJB option. \n\nTip: Ensure you are in the /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0 folder before running the docker build. \n\nThe default-partition0 folder contains the dockerfile used to build the back-end microservice. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0\n\ndocker build -t defaultapp-partition0 . | tee partition0.out\n```\n\nThe dockerfile performs these basic tasks:\n  *\tUses the projects pom.xml file to do a Maven build, which produces the deployable EAR. \n  *\tCopies the EAR file and OpenLiberty Server configuration file to the appropriate location in the Docker container for the microservice to start once the container is started.\n  *\tCopies the Derby Database library and database files to the container\n\n![](images/14-docker-build-partition0.png)\n\n**e.**\tStart the partition-partition0 (back-end) docker container.\n\nNotice the command line options that are required for the microservice to run properly. \n  *\tThe partition-partition0 container exposes port 9096.This is only necessary if we want to hit the Service interface directly while testing.\n  *\tThe container must be included in the defaultappNetwork that you defined earlier. \n\n```\ndocker run --name=defaultapp-partition0 --hostname=defaultapp-partition0 --network=defaultappNetwork -d -p 9096:9080 defaultapp-partition0:latest\n\ndocker ps\n```\n\n![](images/15-docker-ps-2.png)\n \nNote: The application is exposed on port 9096 and running on port 9080 in the container\n\n**f.**\tInspect Dockerâ€™s defaultappNetwork and ensure both microservices are joined in the network\n\n```\ndocker inspect defaultappNetwork\n```\n\n![](images/16-docker-inspect.png)\n\nThe microservices are now running on separate OpenLiberty servers in the local Docker environment. \n\nIn the next section, you will test the microservices application from a web browser.\n\n**_4.** View the OpenLiberty Server logs for the microservices\n\nAt this point, the microservices should be up and running inside of their respective docker containers. \n\nFirst, you look at the OpenLiberty server logs for both microservices to ensure the server and application started successfully. \n\n**a.** View the server log in the partition-web (front-end) docker container by running the following command to view the OpenLiberty Server log in the defaultapp-web container\n\n```\ndocker logs defaultapp-web\n```\n\n![](images/17-docker-logs.png)\n\nYou should see messages indicating the DefaultApplication and the defaultServer have been successfully started and is running.\n\t \n**b.** View the server log in the partition-partition0 (back-end) docker container by running the following command to view the OpenLiberty Server log in the defualtapp-web container\n\n```\ndocker logs defaultapp-partition0\n```\n\n![](images/18-docker-logs-partition0.png)\n    \nYou should see messages indicating the DefaultApplication and the defaultServer have been successfully started and is running.\n\n**_5.** Test the microservices from your local Docker environment\n\nOnce all the containers have started successfully, the DefaultApplication can be opened at http://localhost:9095/\n\nIn this section, you run the microservices based application, using the variety of options in the application user interface. \n\n**a.**\tLaunch a web browser and go to http://localhost:9095/\n \n![](images/19-defaultapp-9095.png)\n  \n**b.**\tClick the **Snoop Servlet** link to invoke it, which is running in the defaultapp-web (front-end) Microservice\n  \nThe Snoop Servlet requires authentication, as defined in the OpenLiberty server configuration. The credentials to access the Snoop servlet is: \n    \nUsername: **user1**\n    \nPassword: **change1me**\n\n![](images/20-login-credentials.png)\n\n  ![](images/21-snoop.png)\n\n**c.**\tClick the Browser back button to return to the **DefaultApplication** main page.\n \n![](images/22-defaultapp-back.png)\n    \nNext, you run the HitCount service. The HitCount service can be run using a variety of options that illustrate different mechanisms of handling application state in JEE applications. \n\nYou learn a little about the application that pertains to run the microservice based application that now makes distributed REST API calls between services.   \n    \nWhen using Mono2Micro for application analysis and microservice recommendations, we chose to separate the WEB UI components into a microservice and place the EJB components that interact with the back-end database into its own microservice. \n\nThis approach provides separation of the front-end from the back-end as a first pass for adopting a microservices architecture for the DefaultApplication. \n\nThis was not the only option, and we understand that further refactoring might be necessary. But this is a good first step to illustrate the capabilities of Mono2Micro.\n\nHere is a brief introduction to the multiple methods of running the HitCount Service. As illustrated below, selecting any of these three (3) options from the application UI, the HitCount service runs using the local Web Container session / state and runs the defaultapp-web (front-end) microservice. \n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\nSelecting the Enterprise Java Bean (JPA) option from the application, the Web front-end microservice calls out to the back-end microservice. \n  * Enterprise Java Bean (JPA)\n\nIt calls the IncrementAction REST service in the defaultapp-container0 container. The REST endpoint invokes an EJB which uses JPA to persist to the Derby database. Using this option also requires a selection for Transaction Type. \n    \n![](images/23-hit-count.png)\n  \n**d.**\tRun the HitCount service, choosing each of the three options below:\n\n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\nYou should see a message in the HTML page indicating the Hit Count value: An ERROR message is displayed in the event of an error. \n \n![](images/24-hit-count-value.png)\n\nTIP: The logging level in the Mono2Micro generated code has been set to **INFO** in the source code. \n\nThis means that logging statements will be generated in the server log file for all inter-partition calls. \n\nIn the defaultapp-web partition, the logs will show calling the IncrementAction Rest service running in defaultapp-partition0 (back-end) service  \n\nIn the defaultapp-partition0 (back-end) partition, the logs will show the response being sent back to the caller. \n\nSince using any of these options above run ONLY in the defaultapp-web (front-end) container, you will not see anything of significance logged in the server log files. This is expected behavior. \n  \n**e.** Run the HitCount service, choosing the Enterprise Java Bean (JPA) option.\n  \n**f.**\tInvoke the HitCount service multiple times, selecting different options for **Transaction Type**ã€‚\n\n**_6.**\tView the server logs from both microservices.\n  \nIn this case, the front-end microservice does call the back-end microservice, and you will see relevant messages in their corresponding log files. \n\n```\ndocker logs defaultapp-web\n\ndocker logs defaultapp-partition0\n``` \n\nOutput from defaultapp-web container \n \n![](images/25-output-web.png)\n\nOutput from defaultapp-partition0 container\n \n![](images/26-output-partition0.png)\n\n**_7.**\tClose the Web Browser window\n\nYou have successfully built run the DefaultApplication that was transformed using the IBM Mono2Micro. \n\nThe converted application has also been deployed locally in Docker containers running OpenLiberty Server, which is ideally suited for Java based microservices and cloud deployments. \n\nNow that you have seen the transformed application in action, it is time to use Mono2Micro and perform the steps that produced the transformed microservices. \n\n### **Part 2**\n#### **7.3. Use Mono2Micro to analyze the Java EE monolith application and recommend microservices partitions**\n\nObjectives\n  *\tLearn how to use the AI-driven Mono2Micro tools to analyze a Java EE monolith and to recommend the different ways it can be partitioned into microservices\n  *\tLearn how to use Mono2Micro tools to further customize the partitioning recommendations \n\nIn this part of the lab, you first pull the Mono2Micro tools from Dockerhub, then you :\n  1).\tRun Mono2Microâ€™s Bluejay tool to analyze the Java source code, instrument it, and produce the analysis files that will be used as input to the Mono2Microâ€™s AI engine. \n  2).\tUse Mono2Microâ€™s Flicker tool to gather time stamps and use case data as you run test cases against the instrumented version of the monolith application. \n  3).\tUse Mono2Microâ€™s Oriole analyzer tool (AIPL) to produce the initial microservices recommendations. \n  4).\tUse Mono2Microâ€™s UI tool to visualize the microservice recommendations and modify the initial recommendations to further customize the microservice recommendations.\n\n![](images/27-m2m-flow.png)\n\n**_1.** Pull the Mono2Micro Images from Dockerhub\n\nAll the four Mono2Micro container images are available from Dockerhub\n  * https://hub.docker.com/r/ibmcom/mono2micro-bluejay\n  * https://hub.docker.com/r/ibmcom/mono2micro-aipl\n  * https://hub.docker.com/r/ibmcom/mono2micro-ui \n  * https://hub.docker.com/r/ibmcom/mono2micro-cardinal\n\n**a.** Download all the Mono2Micro images by issuing the docker pull commands: \n\n```\ndocker pull ibmcom/mono2micro-bluejay\n\ndocker pull ibmcom/mono2micro-aipl\n\ndocker pull ibmcom/mono2micro-ui\n\ndocker pull ibmcom/mono2micro-cardinal\n```\n\n**b.**\tList the docker images. You should see the four images listed\n\n```\ndocker images | grep ibmcom\n```\n\n![](images/28-docker-images.png)\n\n**_2.** Use Flicker and Mono2Micro Bluejay\n\nFor this lab, we have provided the Flicker java program and its required open-source jars in the GitHub repository, that you cloned earlier in the lab. You use Flicker later in the lab, when you run the test case for the application. \n\nPrerequisites for using Flicker: \n  * Flicker requires Java 1.8 or higher for execution.\n  * Flicker also requires two open source jars, and are included in the GitHub repository for this lab: \n  *\tcommons-net-3.6.jar\n  *\tjson-simple-1.1.jar \n\nThe first step in using Mono2Micro is to prepare the monolithâ€™s Java source code for static and dynamic analysis. Mono2Micro Bluejay tool is used to analyze the application source code, instrument it, and produce the analysis in two .json files.\n\nFor the **DefaultApplication** used in this lab, the complete set of source code for the monolith application is already available in a single directory structure cloned from GitHub. \n\nFor this lab, the monolith source files tree can then be found in **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith**  directory. \n\nLetâ€™s begin with the static data collection phase by running Mono2Microâ€™s Bluejay tool to analyze the Java source code, instrument it, and produce the analysis in two .json files. \n\n**a.** Run the Bluejay analysis using the following commands:\n\n```\ncd /home/ibmadmin/m2m-ws-sample\n\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/:/var/application ibmcom/mono2micro-bluejay /var/application/defaultapplication/monolith out\n```\n    \n![](images/29-docker-run.png)\n    \nNote: The command displays the directory where the output files were generated, as illustrated below.\n\nIn this example: /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\n**b.**\tReview the output from Bluejay: \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\nls -al\n```\n\n![](images/30-ls-al.png)\n\nBluejay creates a mirror copy of the input source directory in its parent directory with a **-klu** extension where all the Java files within the entire directory tree will be instrumented to log entry and exit times in each method.  \n\nIn addition to instrumenting the source, Bluejay creates two .json files in the in the monolith-klu directory: \n  *\trefTable.json\n  *\tsymTable.json\n\nThese json file capture various details and metadata about each Java class such as:   \n  *\tmethod signatures\n  *\tclass variables and types\n  *\tclass containment dependencies (when one classes uses another class as a instance variable type, or method return/argument type)\n  *\tclass inheritance\n  *\tpackage dependencies\n  *\tsource file locations\n  *\tetc. \n\nThis static analysis therefore gathers a detailed overview of the Java code in the monolith, for use by Mono2Microâ€™s AI analyzer tool to come up with recommendations on how to partition the monolith application. \n\nFurthermore, this information is also used by Mono2Microâ€™s code generation tool to generate the foundation and plumbing code for implementing each partition as microservices.\n\n**c.**\tLook at an example of the instrumentation in the monolith code.  \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultWebApplication/src/main/java\n\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultWebApplication/src/main/java/HitCount.java\n```\n\nAs illustrated below, you will find **System.out.printlnâ€¦** statements for the entry and exit of each method in the classes. \n\nThis trace data captures the Thread ID and Timestamp during the test case execution flow, which you will perform later in the lab. \n\n![](images/31-hitcount-java.png)\n\n**d.**\tClose the gedit editor window\n\n**e.**\tChange the permissions on monolith-klu directory, so that it can be updated by the current user.  \n\nBluejay runs in a Docker container. By default, Docker runs as **root** user, and therefore all the files in the instrumented monolith directory are owned by root. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication\n\nsudo chmod -R 777 ./monolith-klu\n```\n    \nWhen prompted for a password, enter: **passw0rd**   (That is a numeric zero in passw0rd)\n  \nThe next step is to run test cases against the instrumented monolith application to capture runtime data for analysis. \n\n**_3.** Run test cases using the instrumented monolith for Runtime data analysis\n\nNow you are ready to proceed to the next phase of data collection from the monolith application. This is a crucial phase where both the quantity and quality of the data gathered will impact the quality and usefulness of the partitioning recommendations from Mono2Microâ€™s AI analyzer tool. \n\nThe key concept here is to run as much user scenarios as possible in the running instrumented monolith application, exercising as much of the codebase as possible.  \n\nThese user scenarios (or business use cases if you will), should be typical user threads through the application, related to various functionality that the application provides. More akin to functional verification testcases or larger green thread testcases, and less so unit testcases.\n\nIn the DefaultApplicationâ€™s case, these scenarios are very simple, which is partially why we selected this application for the lab. For real applications, your test cases could be quite extensive in order to achieve maximum code coverage in the tests.  \n\nTest cases for DefaultApplication:\n  *\tRun the Snoop action\n  *\tRun the HitCount action\n\n**_4.** Deploy the instrumented application to Liberty for testing\n\nThe test cases (use cases) that you will run must be executed on the instrumented code base, which is in the **monolith-klu** directory. \n\nAs such, the instrumented code needs to be compiled, new deployment binaries generated, and redeployed to the local Liberty server that you will use to run the test cases. \n\nThe DefaultApplication is a Maven based project. The instrumented application can easily be rebuilt using Maven CLI. Maven version 3.6.3 has been verified to work in this lab. \n\n**a.**\tBuild and package the instrumented version of the DefaultApplication  \n\nThe top-level pom.xml that is used to build and package the application is in the **monolith-klu** folder. You will change to that directory and run the Maven build. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu\n\nmvn clean install\n```\n\nMaven should have successfully built the application and generated the binary artifacts (EAR, WAR), and placed them in the Liberty Server **apps** folder.  Now the application is ready to run test cases.   \n\n![](images/32-mvn-install.png)\n  \n**b.**\tRun the scripts below to Start the Liberty server and check that the server is in the running state\n\nAs a convenience, we have provided simple scripts for you to use to start and stop the Liberty server, as well as check the status of the server. \n\n```\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/startServer.sh\n\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/serverStatus.sh\n```\n    \n![](images/33-server-running.png)\n    \nTip: The Liberty server is in the folder: **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/usr/servers/DefaultApplicationServer**.\n\n**c.**\tOpen a Web Browser and launch the **DefaultApplication** URL: http://localhost:9080\n  \nThe main HTML page will be displayed. \n\nNotice the application only has two main features: \n  * Snoop\n  *\tHit Count\n  \n![](images/34-defaultapp-9080.png)\n\n**_5.** Run the test cases for the DefaultApplication\n\nSince this is a simple application, you will run the test cases manually using the applications web UI. There are only two use cases for this simple application.: Snoop and Hit Count. \n\nAs these use cases are run on the instrumented monolith application, you will use Mono2Microâ€™s Flicker tool to record use case labels and the start and stop times of when that use case or scenario was run.  \n\nThe Flicker tool essentially acts like a stopwatch to record use cases. \n\nThe labels provided to Flicker for each use case should be meaningful as this will come into play later when viewing Mono2Microâ€™s AI analysis where the classes and flow within the code is associated with the use case labels. \n\nFlicker is a simple Java based tool that prompts the user for the use case label, and then records the start time. Then prompts again for the **stop** command after the user finishes running that scenario on the monolith.\n  \n**_5.1.**\tFirst, start the Flicker tool, using the command below in a new Terminal window:\n\n```\ncd /home/ibmadmin/m2m-ws-sample/Flicker\n\njava -cp commons-net-3.6.jar:json-simple-1.1.jar:. Flicker -no_ntp\n```\n\nNotice that Flicker is just waiting for you to provide a **Label** or name of the test case to run. You will do that in the next step.  \n\n![](images/35-flicker-lable.png)\n  \n**_5.2.**\tRun the **Snoop** test case. Follow the steps below to run the Snoop test case.\n\n**a.** In the web browser, go to http://localhost:9080/\n\n**b.**\tFrom Flicker, provide the label named **snoop** and press **ENTER**. This starts Flickerâ€™s stopwatch for the snoop test case. \n \n![](images/36-flicker-snoop.png)\n\n**c.**\tFrom the Web Browser, click on the **Snoop Servlet** link in the DefaultApplication HTML page. Snoop requires basic authentication. If prompted for credentials, enter the following username and password:\n\nUsername: **user1**\n\nPassword: **change1me**   (that is the number 1 in the password).  \n \n![](images/37-snoop-servlet-link.png)\n\n**d.**\tRun snoop multiple times: Just click the Browsers **Reload Page** button. \n**e.**\tWhen finished, click on the Browsers **Back** button   to return to the applications main HTML page. \n**f.**\tIn Flicker, enter **STOP**, to stop Flickers stopwatch for the test case\n\nNote: **STOP** must be in upper-case and is Case Sensitive. \n  \nNotice Flicker has recorded the START and STOP times for the **snoop** test case. These timestamps correspond with the timestamps in the Liberty log file, from the instrumented version of the DefaultApplication running in Liberty. \n  \n![](images/38-flicker-stop.png)\n  \n**_5.3.**\tRun the Hit Count test case. Running the Hit Count test case requires the same basic step as Snoop, but has a few more options to test in the application: \n  \n**a.**\tIn Flicker, provide the label named **hitcount** which will start Flickerâ€™s stopwatch for the snoop test case. \n \n![](images/39-flicker-hitcount.png)\n  \n**b.**\tFrom the Web Browser, click on the Hit Count link in the DefaultApplication HTML page. \n\nHit count displays a JSP page with several options that demonstrate a variety of methods to increment a counter, while maintaining state.  \n\n**c.**\tRun hitcount, choosing each of the following options from the application in the web browser: \n\t\t  \n  * Servlet instance variable\n  * Session state (create if necessary)\n  * Existing session state only\n\n**d.**\tRun hitcount, choosing the following option from the application in the web browser: ** Enterprise Java Bean (JPA)**.\n\nWhen choosing the EJB option, you also must select one of the following Transaction Types, radio buttons:\n  * None\n  * Commit\n  * Rollback\n \nThis action invokes an EJB and uses JPA to persist the increment state to a Derby database. \n\n![](images/40-hit-count-demo.png)\n    \n**e.**\tYou can run HitCount multiple times, choosing different **Transaction Type** options. \n      \n**f.**\tIn Flicker, enter **STOP**, to stop Flickers stopwatch for the test case\n\nNote: **STOP** must be in upper-case and is Case Sensitive. \n\nFlicker has now captured the START and STOP timestamps for the use cases, which corresponds to the timestamps recorded in the Liberty log file from the instrumented version of the DefaultApplication.\n  \n![](images/41-flicker-stop.png)\n    \n**g.**\tIn Flicker, enter **Exit**, to quit Flicker    (Case sensitive, Capital E)\n\n**_5.4.**\tRun the script below to Stop the Liberty server. As a convenience, we have provided simple scripts for you to use to start and stop the Liberty server, as well as check the status of the server. \n\n```\n/home/ibmadmin/m2m-ws-sample/defaultapplication/scripts/stopServer.sh\n````\n\n![](images/42-stopping-server.png)\n\n**_6.** Review the output from Flicker and the Liberty Log file based on the test cases\n\nAfter exiting the Flicker tool, it produces a context json file that captures the use case labels and their start/stop times. The context json files are generated in the same directory where Flicker ran. \n\nThis context json file will be used as input to the AI engine in Mono2Micro for shaping the recommendations for microservices partitioning. \n\n**_6.1** Review the output from Flicker and Liberty log file based on the test cases you executed\n\nTake a quick look at the context file that Flicker generated for the snoop and hit count test cases\n\n**a.**\tView the context json file. \n\nThe name of the context json file contains timestamp in its name. So view the files in the Flicker directory, and then view the **context*.json** file. \n\n```\ncd /home/ibmadmin/m2m-ws-sample/Flicker\n\nls *.json\n\ncat context*.json\n```\n\nNotice the two test cases were recorded, along with the start and stop timestamps for each testcase. \n\n![](images/43-cat-json.png)\n\n**b.**\tView the Liberty log file to ensure the log contains the trace statements from the instrumented version of the application.  \n\n```\ncat /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/usr/servers/DefaultApplicationServer/logs/messages.log\n```\n\nAs illustrated in the screenshot below, the Liberty server log file (messages.log) will include trace data that captures the entry and exit of each Java method called, along with the timestamp of the invocation. \n    \nIf the log file does NOT contain trace statements for Snoop and Hit count as illustrated below, it is likely that the instrumented version of the application was not deployed to the Liberty server. \n\nDo not worry, we have captured a known good log file and Flicker context json file that can be used to continue the lab, without having to go back and redo previous steps.  \n\n![](images/44-message-log.png)\n    \nTip: It is critical that the server log files DO NOT get overwritten during the execution of the test cases. \n\nSystem Administrators configure limits for how much data is logged and kept. \n    \nThey do this by configuring a MAX size for the log files, and the MAX number of log files to keep. If or when these maximum thresholds are reached, Liberty will write over the messages.log file, resulting in the timestamps from our test cases to be out of whack. \n    \nTherefore, it is critical to ensure proper sizing of these logging thresholds to ensure log files are not overwritten when running the test cases.  \n\nSince the tests in this lab are short and simple, there will not be an issue. But something to look out for when running larger test suites. \n\n**_7.** Recap of the data has been collected for the monolith \n\nLetâ€™s review the data that has been collected on the monolith:\n  *\tBluejay generated two table json files containing specific information about the java classes and their relationships via static analysis of the code: \n  *\trefTable.json\n    *\tsymTable.json\n    *\tFlicker generated one or more context json files that contains use case names/labels and their start and stop times\n    *\tAll the standard console output/error log files captured on the application server side as the use cases were being run on the instrumented application \n\nWith these three sets of data, Mono2Micro can now correlate what exact Java classes and methods were executed during the start and stop times of each use case, and thereby associate the observed flow of code within the application to a use case. \n\n![](images/45-m2m-flow.png)\n  \nLetâ€™s proceed to the next phase of using Mono2Micro, which is to run the AI analyzer tool against this data.\n\n**_8.** Running Mono2Microâ€™s AI Analyzer for Application Partitioning Recommendations\n\nMono2Microâ€™s AIPL tool is the analyzer that uses unsupervised machine learning AI techniques to analyze the three sets of data collected on a monolith applicated as done in the previous section.  \n\nOnce you have completed the executing all the test scenarios, you should have the following categories of data collected:\n  * symTable.json\n  * refTable.json\n  * one or more json files generated by Flicker, and\n  * one or more log files containing the runtime traces\n\nPrepare the input directories for running the AIPL tool \n\nTo prepare for the analysis, the input directories and an optional config.ini file need to be gathered and placed (copied) into a common folder structure before running the AIPL tool.  \n\nFor this lab, the input directories have been placed into the following directory structure for you. \n\nThe /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/ directory contains the subdirectories within which the data files are placed:\n  \n**contexts/** - One or more context .json files generated while running the Flicker tool alongside the use case runs\n    \n**logs/** - One or more console logs from the application server as the instrumented monolith was run through the various use cases\n  \n**tables/** - The two table .json files generated by the Bluejay tool \n  \n**config.ini** -  Optional file to configure various parameters for the analysis tool. If one doesnâ€™t exist, AIPL generates one for you with default values. \n \n![](images/46-ls-r.png)\n  \n**_8.1.** Run the AIPL tool to generate the microservices recommendations. \n\nOnce you have completed the data collection process for the Java monolith under consideration, you can feed the data to the AIPL tool to generate microservices recommendations.\n\n**a.**\tChange directory to application-data directory\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data\n```\n\n**b.**\tRun the AIPL tool, using the following command:\n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data:/var/application ibmcom/mono2micro-aipl\n```\n\n![](images/47-docker-run.png)\n    \nWhen the AIPL tool finishes its analysis, it will generate an application partitioning recommendations graph .json file, various reports, and other output files in the mono2micro/mono2micro-output/ subdirectory within the parent directory of the input subdirectories.\n    \nNext. Explore some of the notable files and reports generated by Mono2Micro. \n    \nListed here are some of the notable files that were generated from the AIPL tool\n\n**Cardinal-Report.html** is a detailed report of all the application partitions, their member classes, outward facing classes, etc\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/Cardinal-Report.html**\n\n**Oriole-Report.html** is a summary report of all the application partitions and their associated business use cases\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/Oriole-Report.html**\n\n**final_graph.json** is the full set of application partition recommendations (natural seams and business logic) and associated details, viewable in the Mono2Micro UI\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/oriole/final_graph.json**\n\n**cardinal/** is a folder that contains a complete set of input files (based on the partitioning) for the next and last stage of the Mono2Micro pipeline, running the code generator\n\n**/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-output/cardinal/**\n\n**c.**\tContinue to the next section. You will explore the generated reports later in the lab. \n\n**_8.2**   Use the mono2micro UI to view and manipulate the partitioning recommendations generated from the AIPL tool \n\nLetâ€™s now take a look at the partitioning recommendations Mono2Micro generated by loading the final_graph.json in the graph UI. \n\n**a.**\tLaunch the Mono2Micro UI using the following command:\n\n```\ndocker run -d -p 3000:3000 --name=m2mgui ibmcom/mono2micro-ui\n```\n\n**b.**\tFrom a web browser, navigate to http://localhost:3000/\n \n![](images/48-m2m-ui.png)\n\n**c.**\tLoad the final_graph.json file in the mono2micro UI\n  \n**d.**\tFrom the UI, click the **Drop or Add File** link \n\n**e.**\tFrom the **File Upload** dialog window, navigate to the following final_graph.json file: **Home>ibmadmin>m2m-ws-sample>defaultapplication>mono2micro-analysis>oriole>final_graph.json**.\n\n**f.**\tClick the **Open** button on the File Upload dialog, to load the file into the UI.\n\n![](images/49-m2m-load-json.png)\n \n**g.**\tFrom the UI, click the **X** to SKIP the tour, and proceed to the results\n \n![](images/50-m2m-ui-close-tour.png)\n  \nAs illustrated below, the UI displays the initial recommendations for partitioning the application into microservices. From the UI, you can explore the partition recommendations \n    \n![](images/51-m2m-ui-final-graph.png)\n    \nThe initial partitioning recommendations is a starting point and generated taking into consideration based on the business logic and natural seams that were discovered during the analysis. \n\nAt the time of this writing, there is a known issue in Mono2Micro where in certain cases a class is placed in the Unobserved part despite use cases being run where its use is captured in the logs. This affects Snoop Servlet for this application. However, in the lab, you will slightly customize the partition recommendations to suit our goals, and at that time, you will move the Snoop class into an appropriate partition. This will provide an opportunity to see how easy it is to customize the recommendations to tailor them to exactly suit your desired end state.  \n\nThe Default Application contains two major Java components in the application: **Snoop Servlet** and **HitCount application**.\n\nIn addition to the Java components, the application also contains HTML, JSP, and other web resources. \n\nThe goal of this lab is to split the Default Application monolith into separate microservices, such that the (Front-end) Web components run as a microservice, and the (back-end) EJB and data layer run as a separate microservice.  \n\nIn this exercise, we will ensure that the Web components (Servlets, HTML, JSP, etc) will be in the (front-end) web partition, and the (back-end) HitCountâ€™s increment action Java / EJB components run in a separate partition. \n  \n**h.**\tEnsure the view in the UI to display partitioning recommendations are set to **Business Logic**. \n \n![](images/52-m2m-ui-business-logic.png)\n    \nAlternatively, you can use the pull-down selector to view the recommendations based on **Natural Seems**, Custom Views, or **Data Dependencies**. \n  *\tBusiness logic partitioning is based on the runtime calls from the test cases\n  *\tNatural Seems partitioning is based on the runtime calls and class dependencies.  For example, an Object of class A holds a reference to an object of class B as a variable\n\nFor natural seams-based partitioning, Mono2Micro creates partitions while avoiding inter-partition containment data dependencies â€“ containment data dependencies between classes belonging to different partitions\n  *\tCustom: Customize how your classes are grouped. Start from either the Business logic view or the Natural seams view.\n\n**i.**\tIf you explored other views, return to the **Business Logic** view.  \n  \n![](images/53-m2m-ui-business-logic-2.png)\n\nFrom the Business Logic view, notice that there are three partitions created, and a special partition for **Unobserved** classes. \n  *\tThe Numeric value in the partitions reflects the number of Java classes inside of the partition\n  *\tThe Lines between partitions indicates where classes from one partition make calls to classes in a different partition\n  *\tThe Unobserved partition is a group of classes that were analyzed but were not found to be included in any of the use case test that were executed earlier. This could be due to dead code, or incomplete set of test cases for adequate code coverage. \n\nNOTE: And as noted earlier, there is a bug in the Beta version of Mono2Micro that caused SnoopServlet to be unobserved, even though it was included in a test case.  \n\n**j.**\tExplore the Java classes in partition0, partition1, and partition by double-clicking on each of the partitions to display the classes in each partition\n\n![](images/54-m2m-ui-partitions.png)\n  \n  * Partiton0 contains two classes (Increment and IncrementSSB) which are EJB components that are used to persist increment data to a backend Derby database. \n  * The **Increment** EJB classis called from the **IncrementAction** Java class that is in partition2.  \n  * Partition1 contains the HitCount Servlet, which then calls the IncrementAction Java class in Partition2. \n\n**k.**\tExplore the Java classes in the **Unobserved** group by double-clicking on the Unobserved group to display the classes. This is a group of classes that Mono2Micro analyzed but were not included in any of the test cases. \n\n![](images/55-m2m-ui-unobserved.png)\n  \n  *\tEndpointIT is a class that exists in the Junit Tests in the Java project. We did not run the Junit tests as part of the test cases. Therefore, it is expected that this class is not included in any of the partitions. \n  *\tSnoopServlet is a core class that was included in the snoop test case and should have been included in partition1 along with the HitCount Servlet. This is a known bug in the Mono2Micro beta at the time of this writing. You will move this class to an appropriate partition in the next section of the lab, when we customize the partition recommendations from the Mono2Micro UI. \n\nThe initial partitioning recommendations are a starting point and generated taking into consideration based on the business logic and natural seams that were discovered during the analysis.\n\nIn this lab, you slightly customize the partition recommendations to suit our desired goals while providing an opportunity to see how easy it is to customize the recommendations to tailor them to exactly suit your desired end state.  \n\n**_8.3.** Customizing & Adjusting Partitions\n\nIn order to refine the recommended business logic partitions, letâ€™s consider the classes in partiton1 and the Unobserved group. In these partitions, the classes were servlet classes, as well as a Junit test class. \n\nGiven that the DefaultApplication  monolith has a web based front-end and UI, letâ€™s use one single partition to house all the front-end code for the application, which then would include all html/jsp/etc files, and the Java servlet classes which are referred to by the html file. \n \t\nThe important point to note here is that Java servlets need to be running on the *same* application server instance that serves up the html files referring to the servlets\n\nThe goal of this lab is to split the Default Application monolith into separate microservices such that: \n  *\tThe (Front-end) Web components run as a microservice\n  *\tThe (back-end) EJB and data layer run as a separate microservice\n\nThe partition recommendations from Mono2Micro is a good first step toward partitioning the application for microservices. \n\nThe illustration below shows our desired final state of the partitioning, which will then be used as the basis for the microservice code generation later in the lab. \n\nIn this section of the lab, you use the Mono2Micro UI and tweak the graph to the desired state. \n \n![](images/56-m2m-ui-web-partition0.png)\n  \nTweaking the business logic recommendations is straight forward using the UI, and includes these basic steps, which you will do next: \n  *\tRename partition1 to web. This is not required but illustrates the capability to create partitions with names that make sense. This is useful during the code generation phase. \n  *\tMove SnoopServlet class to the web partition. All the Servlets and other front-end components should be here. \n  *\tMove the IncrementAction class to partition0. This class will become the new REST service class during the code generation phase\n\n**_8.3.1**    Customize the graph\n\nThis section shows how to create a custom view for editing the partitioning recommendations\n  \n**a.**\tTo create a custom view, first select Custom View from the Graph view selection pull-down menu\n \n![](images/57-m2m-ui-custom-view.png)\n  \n**b.**\tSelect Business Logic view as the starting point for the custom view. The click the Start button. \n \n![](images/58-m2m-ui-business-logic-3.png)\n  \n**c.**\tToggle the Edit graph to the **ON** position to allow editing of the graph\n \n![](images/59-m2m-ui-edit-graph.png)\n  \n**d.**\tDouble-click on each of the partitions to view the classes within the partitions and Unobserved group. \n \n![](images/60-m2m-ui-view-classes.png)\n  \n**e.**\tRename **partition1** to **web** by clicking on partition1 that includes the HitCount class\n\n**f.**\tClick on the pencil icon  to rename the partition.  \n \n![](images/61-m2m-ui-rename-partition.png)\n  \n**g.**\tType **web** as the new partition name. Then press **ENTER** key to finalize the name change.\n \n![](images/62-m2m-ui-name-changed.png)\n  \nThe partition has been renamed to **web**.\n\n![](images/63-m2m-ui-name-web.png)\n \n**h.**\tMove the SnoopServlet class to the **web** partition by dragging and dropping the SnoopServlet class from the Unobserved partition to the web partition\n \n![](images/64-m2m-ui-drag-drop.png)\n    \nThe **SnoopServlet** is now located in the web partition.\n  \n![](images/65-m2m-ui-snoopservlet-moved.png)\n    \n**i.**\tMove the **IncrementAction** class from **partition2** to **partition0** by dragging **IncrementAction** class from partition2 to partition0\n \n![](images/66-m2m-ui-drag-drop-2.png)\n  \nThe **IncrementAction** class is now located in partition0\n \n![](images/67-m2m-ui-incrementaction-moved.png)\n  \n**l.**\tClick on the **Save** icon to save the updated custom view. The customized final_graph.json file is saved to the Downloads folder. \n \n![](images/68-m2m-ui-save-changes.png)\n  \n**_8.4** Regenerate the partition recommendations by rerunning AIPL against the customized graph\n\nTo generate the new microservice recommendations and the relevant reports for a modified graph you must execute the AIPL tool with the regen_p option. \n\nAdditionally, the AIPL tool must reference the customized version of the final_graph.json file. To prepare to run the AIPL tool again, you must first do a couple of manual steps: 1).\tMove the customized final_graph.json file from **Downloads** folder to a known location by Mono2Micro. 2).\tRename the customized **final_graph.json** file to a name that makes it obvious this is our customized graph and not the original. 3). \tModify the Mono2Micro **config.ini** file to reference the name and location of the customized graph file. \n\n**_8.4.1.**\tCopy the customized final_graph.json file from users **Downloads** folder to a known location by Mono2Microâ€™s AIPL tool, and name it custom_graph.json\n\nBy default, the AIPL tool will look in the root directory of the application-data folder where the contexts, logs, and tables are located. \n\nThis is the directory structure that was setup for the initial run of the AIPL tool earlier in the lab. All you will do now I copy the final_graph.json file to this folder location where it will be discovered by the AIPL tool. \n    \nRun the following commands to copy the file, change to the target directory, and list the files and ensure the custom_graph.json has been copied to the desired directory\n\n```\ncp /home/ibmadmin/Downloads/final_graph.json /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/custom_graph.json \n\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data\n\nls -l \n```\n  \n![](images/69-ls.png)\n\n**_8.4.2.**\tFrom the same folder as the custom-graph.json, modify the permissions for config.ini so that we have write permissions\n\n```\nsudo chmod 777 ./config.ini \n```\n  \nWhen prompted, enter the sudo password for ibmadmin:  **passw0rd**\n\n**_8.4.3.**\tEdit the config.ini file to reference the new custom_graph.json file to be used for regenerating the partition recommendations. (Use any editor available)\n\n```\ngedit ./config.ini\n```\n\n**a.** Modify the config.ini by changing the value for the **UserModifiedGraph** property to **custom_graph.json**.\n\n**b.**\tSave and Close the config.ini file.\n \n![](images/70-save-config-ini.png)\n\n**_8.4.4.**\tRerun the AIPL tool with the regen_p option to generate the partitioning recommendations based on the updated graph file. \n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data:/var/application ibmcom/mono2micro-aipl regen_p\n``` \n\n![](images/71-docker-run.png)\n\n**_8.4.5.** Explore the generated Cardinal report based on the customized graph and regenerated recommendations from AIPL\n\nThe AIPL created a new folder based on the user modified graph in the following directory: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified**\n\n**a.**\tList the files / folders of the generated directory.\n\n```\nls -l  /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified\n```\n  \n![](images/72-ls-l.png)\n\n**b.**\tView the generated Cardinal report to verify the partitions and exposed services are defined as expected. \n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified\n\nfirefox ./Cardinal-Report-Modified.html\n```\n\nThe Cardinal-Report provides a deep analysis of all the inter-partition invocations, the types of all the non-primitive parameters passed to partitions during their invocations, and foreign class references within a partition. \n\nClasses are foreign to a partition if they are defined in another partition.\n\n![](images/73-m2m-deep-partition-analysis.png)\n  \n**c.**\tReview the partition0 Partition.\n\nPartition0 should include three Member classes:   \n  *\tIncrement\n  *\tIncrementAction\n  *\tIncrementSSB\n\nPartition0 should have one External Facing class:\n  * IncrementAction\n\nMono2Micro detected that there are classes outside of partition0 that call methods on the IncrementAction Class. \n      \nDuring the code generation phase of Mono2Micro, the Cardinal tool will generate a REST service interface for the IncrementAction class, so that other microservices can make the remote method calls in a loosely coupled Microservices architecture. \n  \n![](images/74-m2m-partition0.png)\n    \n**d.**\tReview the web Partition\n\nThe web partition should include two Member classes:\n  *\tHitCount\n  *\tSnoopServlet\n\nThe web partition invokes one class method residing outside of this partition:\n  *\tOutside partition: partition0\n  *\tClass Name IncrementAction\n  *\tMethods:  getTheValue and increment\n\nMono2Micro detected that classes in the web partition call methods in partition0.  \n\nDuring the code generation phase of Mono2Micro, the Cardinal tool will generate a Proxy for the class to call the REST service interface in partition0. \n \n![](images/75-m2m-web-partition.png)\n\n### **Part 3**\n#### **7.4 Generating Initial Microservices Foundation Code**\n\n**Objectives**\n  *\tLearn how to use Mono2Micro tools to generate a bulk of the foundation microservices code, while allowing the monolith Java classes to stay completely as-is without any rewriting \n\nIn this part of the lab, you: \n  * Use Cardinal to generate the microservices plumbing code for the two microservices (front-end and back-end)\n  * Refactor the transformed Microservices\n    * Move the static and non-Java artifacts from the monolith application into the individual microservices\n    *\tRefactor the minimal set of artifacts so that the transformed microservices will compile and run in OpenLiberty server in Docker containers.\n\n![](images/76-m2m-flow.png)\n \nAfter going through the microservice recommendations generated by the mono2micro-aipl container, you can use Mono2Micro to automatically generate API services and related code to realize the microservice recommendations. \n\nThis is accomplished by executing the Cardinal component available as the mono2micro-cardinal container.\n\nCardinal automatically performs three crucial tasks for the architects and developers in the refactoring endeavor of realizing partitions (microservices recommendations) as microservices. \n\nThe tasks performed by Cardinal can be listed as follows: \n  *\tIt creates transformational wrappings to turn partition methods into microservices APIs\n  *\tIt provides an optimized distributed object management, garbage collection, and remote local reference translations like the Java remote method invocation mechanism.\n  *\tIt provides pin-pointed guidance on what the developers should check and manually readjust or tweak code in the generated microservices.\n\n**7.4.1.** Run the Cardinal code generation tool\n\nNow, letâ€™s run the Cardinal code generation tool to generate the plumbing code for the microservices. \n\nThe cardinal code generation tool requires the following input artifacts and is referenced in the cardinal command for proper execution: \n  *\tThe parent folder of the original DefaultApplication monolith application: **/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith**.  \n  *\tThe cardinal folder from the mono2micro-user-modified directory that was generated by the AIPL tool using the regen_p option: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\nFor the lab, you reference a saved version of the cardinal folder when running the cardinal tool. This is just to ensure a known good dataset is used for the code generation: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\nIf you would rather use the cardinal folder that was generated during the lab, use: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified/cardinal**.\n\n**_1.**\tRun Cardinal code generation tool using the following command: \n\n```\ndocker run --rm -it -v /home/ibmadmin/m2m-ws-sample/defaultapplication:/var/application ibmcom/mono2micro-cardinal /var/application/monolith /var/application/mono2micro-analysis-custom/cardinal\n```\n\t\n![](images/77-docker-run.png)\n\n**7.4.2.** Examine the Cardinal Summary report to understand what Cardinal generated for each partition\n\nUpon completion of running cardinal code generation tool, the plumbing code for microservices are generated, along with several reports that provide summary and details of the Java source files that were generated. \n\n**_1.**\tExamine the **CardinalFileSummary.txt** file. \n\nThis file provides a summary of all the files that were generated or modified during the code generation. \n\nThe location of the cardinal reports is in a folder named **cadinal-codegen**. The path to this folder is relative to the **cardinal** input folder specified on the cardinal command line. \n\nIn this case, the cardinal-codegen folder and associated reports are generated here: **/home/ibmadmin/m2m-ws-sample/defaultapplication/application-data/mono2micro/mono2micro-user-modified/cardinal**.\n  \n**a.**\tOpen the CardinalFileSummary.txt file using an available editor\n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal/cardinal-codegen\n\ngedit CardinalFileSummary.txt\n```\n\n**b.**\tExamine the web partition summary in the **CardinalFileSummary.txt** file \n \n![](images/78-cardinal-files-summary.png)\n  \nThis section of the report shows the classes contained in the web partition. The report further denotes the types of classes that are in the partition.\n  *\tProxy classes are created for calling out to a class to an outside partition via REST API. In this case, the HitCount Servlet in the web partition calls the IncrementAction REST Service class in partition0. \n  *\tService classes are generated REST Service interface classes. A service class is generated for each Java class that is receiving proxied requests from one partition to another via REST API. \n  *\tOriginal classes are the classes that already existed in the monolith and will remain in the web partition. In this case, the SnoopServlet and HitCount servlet are kept as original. \n  *\tDummy classes are classes that were in the monolith but will now exist in a different partition. The Dummy classes throw an exception that is defined in the Utility classes that are created in every partition. \n  *\tUtility classes are created to handle the plumbing such as serialization, exceptions, logging, and interfaces for the new microservices.  \n\n**_2.**\tScroll down and examine the **partition0** partition summary in the **CardinalFileSummary.txt** file \n \n![](images/79-cardinal-files-summary-2.png)\n  \nThis section of the report shows the classes contained in the partition0 partition. The report further denotes the types of classes that are in the partition.\n  *\tProxy classes are created for calling out to a class to an outside partition via REST API. \n  *\tService class, IncrementActionService is created based on the web partition calling to the IncrementService in partition1 via REST API. \n  *\tOriginal classes are the classes that already existed in the monolith and will remain in the web partition. In this case, the Increment, IncrementAction, and IncrementSSB classes will remain in the partition0. \n  *\tDummy classes are classes that were in the monolith but will now exist in a different partition. The Dummy classes throw an exception that is defined in the Utility classes that are created in every partition. The SnoopServlet and HitCount Servlet will be in the web partition.\n  *\tUtility classes are created to handle the plumbing such as serialization, exceptions, logging, and interfaces for the new microservices.  \n\n**_3.**\tClose the editor for the CardinalFileSummary.txt file \n\n**7.4.3.** Examine the Java code that was generated by Cardinal\n\nCardinal generates the Java source files in separate folders for each partition and are named according to their respective partitions.  \n\nThe location of the Java source files is in a folder named **-partiton0** and ***-web**. \n\nThe actual folder name is dependent upon the input paths specified on when running the cardinal command. In our case, the actual folder names are: \n  *\tmonolith-web\n  *\tmonolith-partition0\n\nThe root folder for the generated source files is also dependent on the input paths specified when running the cardinal tool.  \n\nIn this case, the monolith-web and monolith-partitio0 folders are generated here: **/home/ibmadmin/m2m-ws-sample/defaultapplication**.\n\nFor the purpose of this lab, it is not necessary to understand the details of all the code that Cardinal generates. However, we strongly recommend learning this before using Mono2Micro with a production application. See APPENDIX A:  Examine the Java Code generated by Mono2Micro provides a detailed look at these generated files.\n\n**7.4.4.** Refactoring Non-Java Parts of Monolith, Further Code Changes, and Deploying Final Partitions as Microservices\n\nAfter Mono2Micro generates the initial microservices plumbing code and places that along with the monolith classes into each partition, the foundations of the microservices are now there. \n\nThat is, each partition is meant to run as a microservice, deployed on an application server (such as WebSphere Liberty) where the monolith classesâ€™ public methods are served up as REST API. Each partition is effectively then a mini version of the original monolith, its folder structure mirroring the original monolith folder and module structure. \n\nIn order to build and run each partition, more than just the Java code is needed of course.  And here is when a key question is usually raised: What exactly does one do with the non-Java parts of the monolith with respect to each partition, and how, in order to facilitate the final goal of running all partitions as microservices?\n\n**One Approach**\n\nOne approach that you will follow for the DefaultApplication example and highly recommend for most Java applications is as follows: \n  *\tCopy *all* the non-Java files in the monolith (i.e. the build config files such mavenâ€™s pom.xml or gradle files, server config files such as WebSphereâ€™s server.xml, Java EE meta-data and deployment descriptors such as application.xml, web.xml, ejb-jar.xml, persistence.xml etc) to *every* partition, following the same directory structure which will partially already exist in each partition. \n  *\tStarting with that as a base, the aim then is to pare down and incrementally reduce the content of all these files (based on knowledge of what functionality each partition entails, and/or through an iterative compile-run-debug process), ending up with just the needed content in each partition. \n  *\tAfter this is done, each partition will indeed be a mini subset of the original monolith and working together with all the other running partitions and finally become microservices that provide the exact same functionality as the original monolith.\n\nAs each partition is now becoming a separate microservice project and will be developed and deployed independent of the other microservices, ideally, you would create Java projects in your favorite IDE and follow these basic steps for new microservice projects: \n  *\tCreate a Java EE web project for each partition and set the runtime target a WebSphere Liberty installation\n  *\tImport the partition from the filesystem into the project\n  *\tEnsure all partitions module folders containing Java source files are correctly configured as source folders within the Eclipse tools, rooted where the package directories are (this includes the monolith module folders as well as the application utility code folder generated by Cardinal. See previous section)\n  *\tBuild the project and observe any compilation errors\n\nIn this lab, you will make the minimal set of changes for the web and partition0 partitions that are required to compile and run the front-end microservice (web) and the back-end microservice (back-end) in Liberty Server in containers.\n\nIt is beyond the scope of this lab to take each microservice through the iterative development process in an IDE. But you will get the point, if you spend a little time reviewing the updates that are done via the provided scripts. Itâ€™s not that extensive for this simple application. \n\n**7.4.4.1.** Move the original non-Java resources from the monolith to the two new partitions\n\nAs described above, the first step is to Copy **all** non-Java files to **every** partition, following the same directory structure which will partially already exist in each of the generated partitions.\n\nFor this lab, a shell script has been provided for you, which will copy all the resources to the partitions. \n\nThis is the first step to refactoring the partitions. Further refactoring of these artifacts is unique to the microservice functionality in each partition.  \n\nThe script performs the following tasks: \n  *\tCopies the various pom.xml files to both partitions\n  *\tCopies all the webapp artifacts (html, jsp, xml) files to both partitions\n  *\tCopies the application EAR resources to both partitions\n  *\tCopies the Liberty server configuration file to both partitions\n  *\tCopies the database configuration files to the back-end partition\n\n**_1.**\tReview the moveResourcesToPartitions.sh shell script.   \n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\ngedit moveResourcesToPartitions.sh\n```\n  \nThe script:\n  * defines a bunch of variables referencing various directories for copying files\n  * uses sudo to change directory permissions to allow write access to the partitions that mono2 micro generated\n\n![](images/80-move-script.png)\n\n  * copies non-java resources from the monolith application to the (front-end) web partition\n    \n![](images/81-move-script-2.png)\n    \n  * script copies non-java resources from the monolith application to the (back-end) partition0 partition\n \n![](images/82-move-script-3.png)\n\n**_2.**\tClose the editor \n\nTo speed up copying files, run the moveResourcesToPartitions.sh script to do it for you. \n\n**_3.**\tRun the script to copy the non-java resources to the partitions\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\n./moveResourcesToPartitions.sh\n```\n\nWhen prompted for a password, enter: **passw0rd**\n\n**_4.**\t Use a graphical File Explorer   or Terminal window to see the non-Java files now in each of the partitions, and in the same directory structure as the original monolith. \n\n**a.**\tNavigate to the following directories to explore the newly added non-Java resources. Refer to the shell script to see what exactly was copied. \n  *\t/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web\n  *\t/home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0\n\n**7.4.4.2.**  Refactor the original non-Java resources as required for the front-end and back-end partitions\n\nAt this point, every partition contains all the Java and non-Java files necessary for the application. \n\nStarting with that as a base, the next step is to pare down and incrementally reduce the content of all these files, ending up with just the needed content in each partition to build and run the microservice. \n\nIn this lab, you will focus only on the refactoring that is required for the partitions to compile and run in Docker containers. An iterative for further paring down the content is beyond the scope of this lab. \n\nTo simplify the refactoring activities for this lab, a shell script has been provided that performs the refactoring required such that each partition (microservice) will compile and run on their own Liberty Server in separate Docker containers.  \n\nThe script performs the following tasks for the web partition:\n  *\tCreate a new pom.xml file to build the Cardinal Utility classes generated by Mono2Micro\n  *\tUpdates the top level pom.xml file to include the Cardinal Utilities module to be built with the app\n  *\tUpdates the DefaultWebApplication pom.xml file to remove Java persistence dependency\n  *\tUpdate the DefaultApplication-ear pom.xml file to remove the database config \n  *\tUpdate the DefaultApplication-ear pom.xml file to add Dependency for Cardinal Utility classes \n  *\tUpdate Liberty server.xml file to remove database / datasource configuration\n  *\tAdd a dockerfile to build the Microservice and Docker image running on Liberty\n\nThe script performs the following tasks for the partition0 partition:\n  *\tCreate a new pom.xml file to build the Cardinal Utility classes generated by Mono2Micro\n  *\tUpdates the top level pom.xml file to include the Cardinal Utilities module to be built\n  *\tUpdates the DefaultWebApplication pom.xml file to remove Java persistence dependency\n  *\tUpdate the DefaultApplication-ear pom.xml file to remove the database config \n  *\tUpdate the DefaultApplication-ear pom.xml file to add Dependency for Cardinal Utility classes \n  *\tUpdate and move the JAXRSConfiguration.java file to DefaultWebApplication class path. \n    *\tUpdate the package in the Java file to match source location in the module.  \n    *\tThis Java file is generated by Mono2Micro\n  *\tUpdate the IncrementActionService.java file \n    *\tThis Java file is generated by Mono2Micro.  \n    *\tThis works around a known issue with conflicting import statements in the Java file \n  *\tAdd a dockerfile to build the Microservice and Docker image running on Liberty\n\n**_1.**\tRun the refactorPartitions.sh shell script to perform the partition refactoring\n\n```\ncd  /home/ibmadmin/m2m-ws-sample/defaultapplication/scripts\n\n./refactorPartitions.sh\n```\n\nWhen prompted for a password, enter: **passw0rd**\n\n![](images/83-refactor-script.png)\n\n![](images/84-refactor-script-2.png)\n \nIn a production application, refactoring the resources within each Microservice could take significant time. \n\nThe aim is to pare down and incrementally reduce the content of all these files (based on knowledge of what functionality each microservice entails) and through an iterative **compile-run-debug** process, ending up with just the needed content for each microservice.\n\nIf you are interested in the details of the refactored files that were pared down for this lab, refer to APPENDIX B in this lab guide. APPENDIX B:  Examine the Refactored resources after code generation provides a detailed look at these refactored files. \n\n**7.4.4.3.**  Deploy Partitions as Containerized Microservices\n\nTo portably run the builds of all the partitions, and at the same time prepare them for containerization, this lab uses Docker based builds right from the start.\n\nMulti-stage dockerfiles are used for each partition: \n  *\tStage 1: Performs the Maven build and packaging of the deployable artifacts (WAR, EAR, JAR)\n  *\tStage 2: Creates the Docker image from OpenLiberty, and adds the application, server configuration, and other configurations required for the partitions (Derby DB config) \n\nThe dockerfile is slightly different for each partition since each partition will require unique configurations for its Microservice.  \n\n**_1.**\tNavigate to the Dockerfile in the web partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/Dockerfile\n```\n  \n![](images/85-dockerfile-web.png)\n\nBuild Image stage: \n  *\tPerforms the Maven Build and package of the application based on the pom.xml files in the project. \n\nProduction Image stage: \n  *\tPulls the Universal base Image (UBI) of Open-Liberty Docker image from Dockerhub. The Universal Base Image is the supported images when deploying to RedHat Openshift. \n  *\tCopy the EAR to the Liberty apps directory, where Liberty will automatically start when the container is started. \n  *\tCopy the Liberty server configuration file to Liberty config directory, which is used to configure the Liberty runtime.\n  *\tAs root user, I install curl as a tool for helping to debug connectivity between Docker containers. This is not required. \n  *\tAs root user, update the permissions on the shared resources folder in Liberty\n\nENV Variables required by Mono2Micro\n\nAdditionally, each partition is passed environment variables specifying the end point URLs for JAX-RS web services in other partitions. \n  *\tThe Cardinal generated code uses these environment variables in the proxy code to call the JAX-RS services\n  *\tIt is important to note that for JAX-RS, URLs cannot contain underscores.   \n\nExample ENV Variable for the web partition: \n  \n**ENV APPLICATION_PARTITION0_REST_URL=http://defaultapp-partition0:9080/rest/**\n\n  *\tWhen running in Docker, a docker network must be set up so that all partitions can communicate with each other. Yu did this in the lab. \n  *\tAll partitions in this lab use port 9080 internally within the Docker environment, but expose themselves on separate ports externally to the host machine\n  *\tUsing this scheme as a base, a Kubernetes deployment can be set up on a cluster where each container acts a Kubernetes service\n\nWhen running in Docker, the hostname must match the **Name** of the container as known in the Docker Network. \n  *\tUse command: **docker network list** to see the list of docker networks\n  *\tUse command: **docker network inspect &ltNETWORKNAME&gt** to see the container names in the Docker network. \n  \nWhere **&ltNETWORKNAME&gt** is the name of the Docker network to inspect\n\n![](images/86-docker-networkname.png)\n\n**_2.**\tNavigate to the Dockerfile in the partition0 partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0/Dockerfile\n```\n\n![](images/87-dockerfile-partition0.png)\n\nBuild Image stage: \n  *\tPerforms the Maven Build and package of the application based on the pom.xml files in the project. \n\nProduction Image stage: \n\nIn addition to the steps that were performed in the web partition, these additional steps are required for the partition0 Microservice deployment. \n  *\tCopies the Derby DB zip file to the shared resources folder for Liberty. The Maven build has a step to unzip the Database contents.\n  *\tCopies the Derby database JDBC library to Libertyâ€™s shared resources folder\n\nNote: The partition0 partition does not require any Mono2Micro ENV variables to be set since this partition doe not make any REST API calls to other partitions. \n\n**7.5.**  Build (Compile) the transformed Microservices using Maven\n\nIn the previous sections of the lab, you used the Mono2Micro tools to transform the original monolith application into two microservices. \n\nThen, using the convenience scripts we provided, you started to refactor the microservices by moving the non-java resources and Liberty configuration into the microservices projects. \n\nYou further refactored the microservices by paring down the non-java configuration files, Liberty configuration, and Maven build artifacts to include only the configuration required to build and run each of the microservices in their own Liberty runtime in containers.  \n\nAt this point, it would be a good idea to do a quick compilation of the microservices to see if there are any compilation or build errors. Then, iterate on the refactoring of each microservice, as needed. \n\nIdeally, developers would do try doing a quick compilation of the generated code by using an IDE tailored to support Java EE and the application server. \n\nUsing an IDE for development is beyond the scope of this lab. Instead, you will simply use Maven to test the compilations of the microservices and observe any compilation errors. \n\n**_1.**\tCompile the monolith-web microservice via command line\n  \n**a.**\tChange to the monolith-web directory, which contains the top-level pom.xml for building the monolith-web microservice \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web\n```\n  \n**b.**\tRun the Maven Build to compile and package the microservice\n\n```\nmvn clean install\n```\n    \nIf all goes well, the microservice project will compile successfully, as illustrated below:\n\n![](images/88-mvn-install-web.png)\n \n**_2.**\tCompile the monolith-partition0 microservice via command line\n\n**a.**\tChange to the monolith-partition0 directory, which contains the top-level pom.xml for building the monolith-web microservice \n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0\n```\n\n**b.**\tRun the Maven Build to compile and package the microservice\n\n```\nmvn clean install\n```\n    \nIf all goes well, the microservice project will compile successfully, as illustrated below:\n\n![](images/89-mvn-install-partition0.png)\n  \n**The last section of the lab below is OPTIONAL!**\n\nAt this point in the lab. you are back to where this lab started. Recall in Part 1 of the lab, you built and ran the DefaultApplication as microservices in containers using Docker. Those microservices were also transformed using Mono2Micro, using resources we provided in the Git Repo. \n\nNow itâ€™s your turn! \n\nTo bring the lab full circle, you may continue to the last section of this lab to build and run YOUR transformed and refactored Microservices application.  \n\n**7.6.** OPTIONAL: Build and run the Transformed Java Microservices Using Docker\n\n**_1.**\tStop and remove the currently running docker containers that you deployed d Part 1 of the lab\n\n```\ndocker stop defaultapp-web\n\ndocker rm defaultapp-web\n\ndocker stop defaultapp-partition0\n\ndocker rm defaultapp-partition0\n\ndocker ps | grep defaultapp\n\ndocker ps -a | grep defaultapp\n```\n  \nNOTE: The docker containers should no longer exist. \n\n**_2.**\tRemove the DefaultApplication Docker images that you created in part 1 of the lab\n\n```\ndocker rmi defaultapp-web\n\ndocker rmi defaultapp-partition0\n\ndocker images | grep defaultapp\n```\n\nNOTE: The docker images should no longer exist. \n\n**_3.**\tBuild and start the defaultapplication-web (front-end) container\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-web\n\ndocker build -t defaultapp-web  . | tee web.out\n\ndocker run --name=defaultapp-web --hostname=defaultapp-web --network=defaultappNetwork -d -p 9095:9080 defaultapp-web:latest\n\ndocker ps | grep defaultapp\n```\n\n**_4.**\tBuild the defaultapplication-partition0 (back-end) container\n\n```\ncd /home/ibmadmin/m2m-ws-sample/defaultapplication/microservices/defaultapp-partition0\n\ndocker build -t defaultapp-partition0 . | tee partition0.out\n\ndocker run --name=defaultapp-partition0 --hostname=defaultapp-partition0 --network=defaultappNetwork -d -p 9096:9080 defaultapp-partition0:latest\n\ndocker ps | grep defaultapp\n```\n  \n![](images/90-docker-ps.png)\n  \nOnce all the containers have started successfully, the DefaultApplication can be opened at http://localhost:9095/\n \nThat completes the end-to-end lab: Using Mono2Micro to transform a Java monolith application to Microservices. \n\n### Conclusion\n\nIn this lab, you gained significant hands on experience using Mono2Micro in a full end-to-end flow. \n\nYou started by building and running the final transformed microservices based application in Docker containers running on Liberty server. \n\nThen, you started from the beginning with a Java EE monolith application, using the AI-driven Mono2Micro tools to analyze it and recommend the different ways it can be partitioned for potential microservices. \n\nUsing Mono2Microâ€™s UI, you further customized the partitioning to suit our specific requirements. \n\nYou then used the unique code generation tool to generate a bulk of the foundation microservices code, while allowing the monolith Java classes to stay completely as-is without any rewriting. \n\nAnd then with further manual refactoring of the non-Java aspects of the monolith, a set of microservices are deployed in containers that provides the exact same functionality as the monolith application.\n\n\n### **Appendix A:  Examine the Java Code generated by Mono2Micro**\n\n**A.1.**   Explore Cardinal some notable Java resources generated in the web partition\n\nFully exploring all the resources in detail is beyond the scope of this lab. You will explore a few of the key resources in the partitions. Feel free to explore in more detail if you desire. \n\n**1.**\tUsing the File Explorer, navigate to the monolith-web directory **Home > m2m-ws-sample > defaultapplication > monolith-web**.\n\n**2.**\tFirst, letâ€™s look at the UTILITY classes in the application subdirectory of the **monolith-web** folder. \n\nNotice the folder named **application**.  This folder contains the Utility classes that handles the plumbing for the microservices. It has classes for handling serialization, exceptions, logging, etc. These classes are generated for ALL partitions. \n\n![](images/a1-1-monolith-web.png)\n\n![](images/a1-2-util.png)\n \nTip: The default name for the Utility classes is **application**. However, this is configurable in the app_config.txt file that is generated by the AIPL tool.  \n \n![](images/a1-3-app-config.png)\n  \nThe **app_config.txt** file is located here: **/home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal**.\n\n**3.**\tExplore the DefaultWebAplication subdirectory in the monolith-web folder. \n\n  *\tOriginal classes: The original HitCount.java and SnoopServlet classes are copied directly from the original monolith application\n \n![](images/a1-4-java.png)\n   \n  *\tProxy class: Cardinal generated a proxy class for IncrementAction. The proxy invokes the IncrementActionService URL in partition0.\n \n![](images/a1-5-defaultapp.png)\n   \n  * Dummy classes: Cardinal generated Dummy classes for classes that are present in the original monolith but are moved to a different partition. The Dummy classes simply throw custom exceptions in the event these classes are unexpectedlyinvoked.   \n\n  Dummy classes for Increment.java and IncrementSSB.java were generated. \n \n![](images/a1-6-defaultapp-2.png)\n\n**A.2.**   Explore Cardinal some notable Java resources generated in the partition0 partition\n\nFully exploring all the resources in detail is beyond the scope of this lab. You will explore a few of the key resources in the partitions. Feel free to explore in more detail if you desire. \n\n**1.**\tUsing the File Explorer, navigate to the **monolith-partition0** directory: **Home > m2m-ws-sample > defaultapplication > monolith-partition0**.\n\nThe UTILITY classes in the application subdirectory of the monolith-partition0 partition are the same as those generated in the web partition. These utility classes are required from each microservice.   \n\nNotice the folder named **application**.  This folder contains the Utility classes that handles the plumbing for the microservices. It has classes for handling serialization, exceptions, logging, etc. These classes are generated for ALL partitions.  \n \n![](images/a2-1-monolith-partition0.png)\n\n![](images/a2-2-util.png)\n\nCardinal generated a Java resource named **JAXRSConfiguration.java**. This file is in the **config** sub-directory under the application subdirectory of the monolith-partition0 partition.  \n    \n![](images/a2-3-config.png)\n \nAs part of the utility code that Cardinal generates, a JAXRSConfiguration class is generated per partition. \n\nFor now, it is important to know this class sets up the JAX-RS config where all service classes are registered and is meant to be copied over and placed in one Java EE module of your preference within each partition. You will work with this file later in the lab as you do final preparation of the microservices for deployment to Liberty Servers in Containers. \n \n![](images/a2-4-jaxrs-config.png)\n \n**user_defined.txt** - A related file that you might notice is the presence of a user_defined.txt file in /home/ibmadmin/m2m-ws-sample/defaultapplication/mono2micro-analysis-custom/cardinal which the Cardinal tool reads on start-up, if one exists. \n\nThis is a way to provide a list of one or more monolith classes that are to be treated as **external facing**, where classes outside its partition might call into it. These external facing classes are also called **service classes** in Mono2Micro nomenclature. \n\nRecall that the deep partition analysis report Cardinal-Report.html generated by AIPL lists all external facing classes per partition that the AI analysis deemed necessaryâ€¦ but there could always be cases where some classes were not called out as such (typically due to insufficient use cases being run that allows Mono2Micro to observe this external facing behavior). \n\nThe user_defined.txt file provides the ability to define additional Java classes as external facing **service classes**, if needed. \n\n**2.**\tExplore the DefaultWebApplication subdirectory in the monolith-partition0 folder. \n  * Original classes: The original classes are copied directly from the original monolith application: \n    *\tIncrement.java\n    *\tIncrementAction.java\n    *\tIncrementSSB.java\n\n![](images/a2-5-defaultapp.png)\n \n  * Service class: Cardinal generated a Service class names IncrementActionService. The service class is the REST Service interface to the IncrementAction service.\n \n![](images/a2-6-defaultapp-2.png)\n\n![](images/a2-7-incrementaction-class.png)\n   \n  *\tDummy classes: Cardinal generated Dummy classes for classes that are present in the original monolith but are moved to a different partition. The Dummy classes simply throw custom exceptions in the event these classes are unexpectedlyinvoked.   \n\n  Dummy classes for HitCount.java and SnoopServlet.java were generated. \n \n![](images/a2-8-java.png)\n\n### **Appendix B: Examine the Refactored resources after code generation** \n\nIn this appendix, you will explore a variety of refactored resources that are representative of the types of refactoring required from many Java application. We will not explore every refactored file. However. You may explore deeper, if desired.  \n\n**B.1.** Cardinal Utility Code Module\n\nFirst, to build the generated Cardinal utility code in each partition, this lab we kept the generated application/ folder, but you could have chosen to rename it to something like to cardinal-utils/ to better identify the modules purpose. \n\nThen, we put together a **pom.xml** fashioned after the monolithâ€™s web moduleâ€™s pom files, to build it as a utility .jar (with the aim of then including it as an additional module in the partition .ear file):\n\n**1.**\tNavigate to the new **Cardinal Utilities** pom.xml file to view its contents in the web partition. This file was created in ALL partitions. \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/application/pom.xml\n```\n\nThis pom.xml file will build a Cardinal Utilities jar file and be included in the partition. The top level pom.xml file was also refactored to include this module for Maven to build\n  \n![](images/b-1-pom.png)\n   \n**B.2.** Partitions Build Config\n\nNext, for each partition, the root pom.xml that was copied from the monolith was modified to include the new cardinal-utils module.\n\n**1.**\tNavigate to the top-level pom.xml file in the web partition to view this update. This update was made to all the top-level pom.xml in each partition.  \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/pom.xml\n```\n\nThe included module to build the Cardinal Utilities must match the **artifactID** in the Cardinal Utils pom.xml that you explored above. \n\nIn this case, it is **application**. It might have been better to rename the module to something like cardinal-utils. But that could be done in another round of refactoring.  \n  \n![](images/b-2-pom.png)\n\n**B.3.** JAX-RS Configuration\n\nNext look at how to facilitate the JAX-RS code generated by Mono2Micro as these partitions are run on the app server. \n\nFirst, as part of the utility code that Cardinal generates, a JAXRSConfiguration class is generated for each partition that has one or more service classes. A service class is class generated by Cardinal that handle incoming REST API calls from outside of the partition.  \n\nThis JAXRSConfiguration class sets up the JAX-RS config where all service classes are registered and is meant to be copied over and placed in one Java EE module of your preference within each partition so that it is in the serverâ€™s class path. \n\nFor this DefaultApplication example, partition0 partition is the only partition that has a service class. I chose to place the java file in the web module in partitton0, in the same source location as the IncrementActionService class. \n\n**1.**\tNavigate to the JAXRSConfiguration java file in the partition0 partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-partition0/DefaultWebApplication/src/main/java/com/ibm/defaultapplication/JAXRSConfiguration.java\n```\n\nYou must specify the package for the class based on where you place the file in the project. \n\nNotice that this class registered the IncrementActionService class that Cardinal generated. \n  \n![](images/b-3-jaxrs-config.png)\n    \n**B.4.** Application Server Config Per Partition\n\nFor this DefaultApplication example, the Liberty server config (server.xml) that originally came in the monolith was copied to each partitions ear module. \n  *\tThe contents of the monolithâ€™s server.xml were **as-is** for parttion0 partition.\n  *\tThe Datasource configuration was removed from the server.xml in the web partition\n\t\nUsually the Liberty server.xml can be further customized and reduced to pull in only applicable server features to each partition.  \n\nIf the original monolith was running on a traditional WebSphere server, and you wish to run the partitions on Liberty, a server.xml can either be handcrafted, or created with the assistance of IBMâ€™s other migration and modernization tools. \n\nOf course, this would only be possible if the monolith uses functionality that WebSphere Liberty supports.  \n\nAdditionally, each partitionâ€™s server.xml also needs to add JAX-RS related features if they already donâ€™t exist, in order to facilitate the generated codeâ€™s JAX-RS webservice service and client code: \n\n<feature>jaxrs-2.0</feature>\n<feature>mpConfig-1.2</feature>\n<feature>mpOpenAPI-1.0</feature>\n\n**1.**\tNavigate to the server.xml file in the web partition to view this update.   \n\n```\ngedit /home/ibmadmin/m2m-ws-sample/defaultapplication/monolith-web/DefaultApplication-ear/src/main/liberty/config/server.xml\n```\n\n![](images/b-4-server-xml.png)\n\n### Appendix C: How can I do this lab using my own environment? \n\nIt is possible to do this lab using your own environment instead of the Skytap environment provided. \n\nNOTE: The prerequisite software listed in the prerequisites section of the lab MUST be installed on your local environment. \n\nThere were only 3 changes that we had to do, in addition to the obviously issuing commands using your own path instead of /home/ibmadmin:\n \n**Section # 7.3 - Run test cases using the instrumented monolith for Runtime data analysis**\n  *\tEdit the scripts m2m-ws-sample/defaultapplication/scripts/startServer.sh and m2m-ws-sample/defaultapplication/scripts/serverStatus.sh to adjust the path to your own environment\n  * OR run the commands manually\n\n```\n$LAB_HOME/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/bin/server start DefaultApplicationServer\n\n$LAB_HOME/m2m-ws-sample/defaultapplication/monolith-klu/DefaultApplication-ear/target/liberty/wlp/bin/server status DefaultApplicationServer\n```\n\n**Section # 7.4.4.1 - Move the original non-Java resources from the monolith to the two new partitions**\n  *\tEdit moveResourcesToPartitions.sh to adjust the path to your own environment, here: WORKDIR=\"$LAB_HOME/m2m-ws-sample\")\n \n**Section # 7.4.4.2 - Refactor the original non-Java resources as required for the front-end and back-end partitions**\n  *\tEdit $LAB_HOME/m2m-ws-sample/defaultapplication/scripts/refactorPartitions.sh to adjust the path to your own environment, here: WORKDIR=\"$LAB_HOME/m2m-ws-sample\"\n\n### **Appendix D: How to use Copy / Paste between local desktop and Skytap VMs**\n\nIn SkyTap, you will find that any text copied to the clipboard on your local workstation is not available to be pasted into the VM on SkyTap. You have to use the copy / Paste capabilities between the lab document on your local workstation to the VM is a good approach to more efficiently work through a lab, while reducing the typing errors that often occur when manually entering data. \n\n**1.** First copy the text you intend to paste, from the lab document, to the clipboard on your local workstation, as you always have (CTRL-C)\n\n**2.** Return to the SkyTap environment and click on the Clipboard at the top of the SkyTap session window. \n \n![](images/d-1-clipboard.png)\n  \n**3.** Use **CTRL-V** to paste the content into the Copy/paste VM clipboard. Or use the paste menu item that is available in the dialog, when you right mouse click in the clipboard text area. \n \n![](images/d-2-clipboard-2.png)\n  \n**4.** Once the text is pasted, just navigate away to the VM window where you want to paste the content. Then, use CTRL-C, or right mouse click & us the paste menu item to paste the content. \n \n![](images/d-3-paste.png)\n  \nThe text is pasted into the VM.\n\n![](images/d-4-paste-done.png)\n \nNote: The very first time you do this, if the text does not paste, you may have to paste the contents into the Skytap clipboard twice. This is a known Skytap issue. It only happens on the 1st attempt to copy / paste into Skytap. \n","fileAbsolutePath":"/home/runner/work/modernization-playbook/modernization-playbook/src/pages/applications/m2m/index.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}