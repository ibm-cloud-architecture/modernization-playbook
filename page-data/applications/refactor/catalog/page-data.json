{"componentChunkName":"component---src-pages-applications-refactor-catalog-mdx","path":"/applications/refactor/catalog/","result":{"pageContext":{"frontmatter":{"title":"Refactoring Java EE Applications","description":"A example of refactoring a Java EE Application to Micro Services"},"relativePagePath":"/applications/refactor/catalog.mdx","titleType":"append","MdxNode":{"id":"134e0cc8-56fe-551e-835a-e0ddbbb63feb","children":[],"parent":"9b8e6a3d-57d7-5443-bec9-22e02ceb8485","internal":{"content":"---\ntitle: Refactoring Java EE Applications\ndescription: A example of refactoring a Java EE Application to Micro Services\n---\n\nexport const Title = () => (\n  <span>\nRefactoring Java EE Applications<br/> <h2>Using the strangler pattern</h2>\n  </span>\n);\n\n<PageDescription>\n\nUsing the strangler pattern\n\n</PageDescription>\n\n<AnchorLinks small>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Refactor the Catalog service to Quarkus</AnchorLink>\n  <AnchorLink>Analyze the Mono2Micro results</AnchorLink>\n  <AnchorLink>The Quarkus Event Producer</AnchorLink>\n  <AnchorLink>The Event Consumer</AnchorLink>\n  <AnchorLink>Run this solution</AnchorLink>\n  <AnchorLink>Summary</AnchorLink>\n</AnchorLinks>\n\n\n## Introduction\nIn this phase the backend application was analyzed and the Catalog service was identified as a candidate to be extracted in to it's own Micro Service. The code was strangled from the monolith and deployed using Quarkus allowing the service to be developed, deployed and scaled independently of the rest of the application code.\n\n### Refactor the Catalog service to Quarkus\nThe [Mono2Micro](http://ibm.biz/Mono2Micro) tool was used to identify the `Catalog` service as a good candidate to become it's own service. In this scenario, the `Catalog` service handles information about the items in the store such as prices, titles, ratings and descriptions. When this information changes the store front as well as the items in the users carts should be updated.\n\n  ![Step 6](images/step6.png)\n\n### Analyze the Mono2Micro results\nRunning Mono2Micro is out of the scope of this article but detailed steps can be found [here](http://heidloff.net/article/step-by-step-instructions-mono2micro/).\n\n  ![m2m](images/mono2mircro-3-partitions-1.png)\n\nThe purple rectangle is essentially the catalog service (except of the missing Category class).\n\nThe green classes make up the remaining monolith (except of Address).\n\nThe red classes need to be assigned to either the catalog service of the remaining monolith dependent of class dependencies. Most of them are exceptions which weren’t covered in the use cases.\n\n### The Quarkus Event Producer\nIn order to display the new price, the order service (the remaining monolith) could invoke a synchronous REST API of the catalog service. However, in order to minimize the coupling between the components, we will use events instead.\n\nHere is the [code](https://github.com/nheidloff/application-modernization-javaee-quarkus/blob/master/service-catalog-quarkus-synch/src/main/java/com/ibm/catalog/ProductResource.java) of the ‘strangled’ catalog service which has been implemented with Quarkus. The application uses MicroProfile and Kafka to send events asynchronously.\n\n```\n@PUT\n@Consumes(\"application/json\")\n@Produces(\"application/json\")\n@Path(\"/CustomerOrderServicesWeb/jaxrs/Product/{id}\")\n@Transactional\npublic Product update(@PathParam(\"id\") Long id, Product updatedProduct) {\n   Product existingProduct = entityManager.find(Product.class, id);\n   if (existingProduct == null) {\n      throw new WebApplicationException(Response.Status.BAD_REQUEST);\n   }\n   existingProduct.price = updatedProduct.price;\n   entityManager.persist(existingProduct);\n   sendMessageToKafka(existingProduct.id, existingProduct.price);\n   return existingProduct;\n}\n\n@ConfigProperty(name = \"kafka.bootstrap.servers\")\nString kafkaBootstrapServer;\n\n@Inject\nVertx vertx;\n\nprivate KafkaProducer<String, String> producer;\n\n@PostConstruct\nvoid initKafkaClient() {\n   Map<String, String> config = new HashMap<>();\n   config.put(\"bootstrap.servers\", kafkaBootstrapServer);\n   config.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n   config.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n   producer = KafkaProducer.create(vertx, config);\n}\n\npublic void sendMessageToKafka(Long productId, BigDecimal price) {\n   String productIdString = productId.toString();\n   String priceString = price.toString();\n   try {\n      KafkaProducerRecord<String, String> record = KafkaProducerRecord.create(\"product-price-updated\", productIdString + \"#\" + priceString);\n      producer.write(record, done -> System.out.println(\"Kafka message sent: product-price-updated - \" + productIdString + \"#\" + priceString));\n   } catch (Exception e) {\n   }\n}\n```\n\n### The Event Consumer\nThe remaining monolith runs on Open Liberty. In order to prevent synchronous invocations of the catalog service, it caches the changed prices in it’s own Db2 database in a new column.\n\n  ![db2](images/strangler-caching.png)\n\nHere is the [code](https://github.com/nheidloff/application-modernization-javaee-quarkus/blob/master/monolith-open-liberty-cloud-native/src/main/java/org/pwte/example/ProductPriceChanged.java) of the remaining monolith which also uses MicroProfile.\n\n```\nimport org.eclipse.microprofile.reactive.messaging.Incoming;\nimport javax.enterprise.context.ApplicationScoped;\nimport org.pwte.example.service.CustomerOrderServicesImpl;\nimport javax.inject.Inject;\n\n@ApplicationScoped\npublic class ProductPriceChanged {\n\n@Inject\nCustomerOrderServicesImpl customerOrderServices;\n\n@Incoming(\"product-price-updated\")\npublic String process(String message) {\n   String productId = \"\";\n   String newPrice = \"0\";\n   try {\n      productId = message.substring(0, message.indexOf(\"#\"));\n      newPrice = message.substring(message.indexOf(\"#\") + 1, message.length());\n      customerOrderServices.updateLineItem(productId, newPrice);\n   }\n   catch (Exception e) {}\n      return message;\n   }\n}\n```\n\n### Run this solution\nUse the following steps to run this solution locally on Docker\n\n```\n$ git clone https://github.com/IBM/application-modernization-javaee-quarkus.git && cd application-modernization-javaee-quarkus\n$ ROOT_FOLDER=$(pwd)\n$ sh ${ROOT_FOLDER}/scripts-docker/build-and-run-monolith-db2.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/run-database-postgres-catalog.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/run-kafka.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/build-and-run-catalog.sh\n```\n\n## Summary\nThis application has been refactored in a series of steps from the original [WebSphere ND v8.5.5 version](https://github.com/ibm-cloud-architecture/cloudpak-for-applications/tree/was855) to run as Micro Services on Red Hat OpenShift.\n","type":"Mdx","contentDigest":"08f29f97843944856d6604332e3c2cf3","counter":463,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Refactoring Java EE Applications","description":"A example of refactoring a Java EE Application to Micro Services"},"exports":{},"rawBody":"---\ntitle: Refactoring Java EE Applications\ndescription: A example of refactoring a Java EE Application to Micro Services\n---\n\nexport const Title = () => (\n  <span>\nRefactoring Java EE Applications<br/> <h2>Using the strangler pattern</h2>\n  </span>\n);\n\n<PageDescription>\n\nUsing the strangler pattern\n\n</PageDescription>\n\n<AnchorLinks small>\n  <AnchorLink>Introduction</AnchorLink>\n  <AnchorLink>Refactor the Catalog service to Quarkus</AnchorLink>\n  <AnchorLink>Analyze the Mono2Micro results</AnchorLink>\n  <AnchorLink>The Quarkus Event Producer</AnchorLink>\n  <AnchorLink>The Event Consumer</AnchorLink>\n  <AnchorLink>Run this solution</AnchorLink>\n  <AnchorLink>Summary</AnchorLink>\n</AnchorLinks>\n\n\n## Introduction\nIn this phase the backend application was analyzed and the Catalog service was identified as a candidate to be extracted in to it's own Micro Service. The code was strangled from the monolith and deployed using Quarkus allowing the service to be developed, deployed and scaled independently of the rest of the application code.\n\n### Refactor the Catalog service to Quarkus\nThe [Mono2Micro](http://ibm.biz/Mono2Micro) tool was used to identify the `Catalog` service as a good candidate to become it's own service. In this scenario, the `Catalog` service handles information about the items in the store such as prices, titles, ratings and descriptions. When this information changes the store front as well as the items in the users carts should be updated.\n\n  ![Step 6](images/step6.png)\n\n### Analyze the Mono2Micro results\nRunning Mono2Micro is out of the scope of this article but detailed steps can be found [here](http://heidloff.net/article/step-by-step-instructions-mono2micro/).\n\n  ![m2m](images/mono2mircro-3-partitions-1.png)\n\nThe purple rectangle is essentially the catalog service (except of the missing Category class).\n\nThe green classes make up the remaining monolith (except of Address).\n\nThe red classes need to be assigned to either the catalog service of the remaining monolith dependent of class dependencies. Most of them are exceptions which weren’t covered in the use cases.\n\n### The Quarkus Event Producer\nIn order to display the new price, the order service (the remaining monolith) could invoke a synchronous REST API of the catalog service. However, in order to minimize the coupling between the components, we will use events instead.\n\nHere is the [code](https://github.com/nheidloff/application-modernization-javaee-quarkus/blob/master/service-catalog-quarkus-synch/src/main/java/com/ibm/catalog/ProductResource.java) of the ‘strangled’ catalog service which has been implemented with Quarkus. The application uses MicroProfile and Kafka to send events asynchronously.\n\n```\n@PUT\n@Consumes(\"application/json\")\n@Produces(\"application/json\")\n@Path(\"/CustomerOrderServicesWeb/jaxrs/Product/{id}\")\n@Transactional\npublic Product update(@PathParam(\"id\") Long id, Product updatedProduct) {\n   Product existingProduct = entityManager.find(Product.class, id);\n   if (existingProduct == null) {\n      throw new WebApplicationException(Response.Status.BAD_REQUEST);\n   }\n   existingProduct.price = updatedProduct.price;\n   entityManager.persist(existingProduct);\n   sendMessageToKafka(existingProduct.id, existingProduct.price);\n   return existingProduct;\n}\n\n@ConfigProperty(name = \"kafka.bootstrap.servers\")\nString kafkaBootstrapServer;\n\n@Inject\nVertx vertx;\n\nprivate KafkaProducer<String, String> producer;\n\n@PostConstruct\nvoid initKafkaClient() {\n   Map<String, String> config = new HashMap<>();\n   config.put(\"bootstrap.servers\", kafkaBootstrapServer);\n   config.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n   config.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n   producer = KafkaProducer.create(vertx, config);\n}\n\npublic void sendMessageToKafka(Long productId, BigDecimal price) {\n   String productIdString = productId.toString();\n   String priceString = price.toString();\n   try {\n      KafkaProducerRecord<String, String> record = KafkaProducerRecord.create(\"product-price-updated\", productIdString + \"#\" + priceString);\n      producer.write(record, done -> System.out.println(\"Kafka message sent: product-price-updated - \" + productIdString + \"#\" + priceString));\n   } catch (Exception e) {\n   }\n}\n```\n\n### The Event Consumer\nThe remaining monolith runs on Open Liberty. In order to prevent synchronous invocations of the catalog service, it caches the changed prices in it’s own Db2 database in a new column.\n\n  ![db2](images/strangler-caching.png)\n\nHere is the [code](https://github.com/nheidloff/application-modernization-javaee-quarkus/blob/master/monolith-open-liberty-cloud-native/src/main/java/org/pwte/example/ProductPriceChanged.java) of the remaining monolith which also uses MicroProfile.\n\n```\nimport org.eclipse.microprofile.reactive.messaging.Incoming;\nimport javax.enterprise.context.ApplicationScoped;\nimport org.pwte.example.service.CustomerOrderServicesImpl;\nimport javax.inject.Inject;\n\n@ApplicationScoped\npublic class ProductPriceChanged {\n\n@Inject\nCustomerOrderServicesImpl customerOrderServices;\n\n@Incoming(\"product-price-updated\")\npublic String process(String message) {\n   String productId = \"\";\n   String newPrice = \"0\";\n   try {\n      productId = message.substring(0, message.indexOf(\"#\"));\n      newPrice = message.substring(message.indexOf(\"#\") + 1, message.length());\n      customerOrderServices.updateLineItem(productId, newPrice);\n   }\n   catch (Exception e) {}\n      return message;\n   }\n}\n```\n\n### Run this solution\nUse the following steps to run this solution locally on Docker\n\n```\n$ git clone https://github.com/IBM/application-modernization-javaee-quarkus.git && cd application-modernization-javaee-quarkus\n$ ROOT_FOLDER=$(pwd)\n$ sh ${ROOT_FOLDER}/scripts-docker/build-and-run-monolith-db2.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/run-database-postgres-catalog.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/run-kafka.sh\n$ sh ${ROOT_FOLDER}/scripts-docker/build-and-run-catalog.sh\n```\n\n## Summary\nThis application has been refactored in a series of steps from the original [WebSphere ND v8.5.5 version](https://github.com/ibm-cloud-architecture/cloudpak-for-applications/tree/was855) to run as Micro Services on Red Hat OpenShift.\n","fileAbsolutePath":"/home/runner/work/modernization-playbook/modernization-playbook/src/pages/applications/refactor/catalog.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}